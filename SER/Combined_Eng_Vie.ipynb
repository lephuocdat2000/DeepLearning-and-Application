{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Combined_Eng_Vie.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1FqDZr9JiXA2J4vxPLgLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/DeepLearning-and-Application/blob/main/SER/Combined_Eng_Vie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zuqdgUiqa1_",
        "outputId": "90a2dce7-4909-4ea2-d03d-58d8a462b8c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnMt--ppqhDO"
      },
      "source": [
        "import scipy.io.wavfile\n",
        "import numpy as np\n",
        "import sys\n",
        "import glob \n",
        "import librosa\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "from IPython.display import Audio\n",
        "### Time Distributed ConvNet imports ###\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import Image\n",
        "from glob import glob\n",
        "import pickle\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from numpy import load\n",
        "### Audioimport ###\n",
        "import IPython\n",
        "\n",
        "### Warning ###\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpM5loWWqqvk"
      },
      "source": [
        "#Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB_QJErZq7w_"
      },
      "source": [
        "Load Vie-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t4xy6m4qndP"
      },
      "source": [
        "vie_vie_X_test = load('/content/drive/MyDrive/Nhận dạng/vie-vie/vie_vie_X_test.npy')\n",
        "vie_vie_X_train = load('/content/drive/MyDrive/Nhận dạng/vie-vie/vie_vie_X_train.npy')\n",
        "vie_vie_y_test = load('/content/drive/MyDrive/Nhận dạng/vie-vie/vie_vie_y_test.npy')\n",
        "vie_vie_y_train = load('/content/drive/MyDrive/Nhận dạng/vie-vie/vie_vie_y_train.npy')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xxxdHiRrjGN"
      },
      "source": [
        "Load Eng-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BObsTUEarbzl"
      },
      "source": [
        "eng_vie_X_train = load('/content/drive/MyDrive/Nhận dạng/eng-vie/eng-vie_X_train.npy')\n",
        "eng_vie_y_train = load('/content/drive/MyDrive/Nhận dạng/eng-vie/eng-vie_y_train.npy')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWm3AQJtrvfS"
      },
      "source": [
        "#Time distributed parameters\n",
        "win_ts = 128\n",
        "hop_ts = 64\n",
        "\n",
        "# Split spectrogram into frames\n",
        "def frame(x, win_step=128, win_size=64):\n",
        "    nb_frames = 1 + int((x.shape[2] - win_size) / win_step)\n",
        "    frames = np.zeros((x.shape[0], nb_frames, x.shape[1], win_size)).astype(np.float32)\n",
        "    for t in range(nb_frames):\n",
        "        frames[:,t,:,:] = np.copy(x[:,:,(t * win_step):(t * win_step + win_size)]).astype(np.float32)\n",
        "    return frames\n",
        "\n",
        "eng_vie_X_train = frame(eng_vie_X_train, hop_ts, win_ts)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7cdB4LSsNK5"
      },
      "source": [
        "Combine Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD6uwxWYsMCb"
      },
      "source": [
        "X_ = np.concatenate((vie_vie_X_test,vie_vie_X_train,eng_vie_X_train))\n",
        "y_ = np.concatenate((vie_vie_y_test,vie_vie_y_train,eng_vie_y_train))\n",
        "\n",
        "#Split train and test set\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_,y_,test_size=0.2,random_state=42)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATMoZ3dMtOvG"
      },
      "source": [
        "Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFg32Uz7tORm"
      },
      "source": [
        "#Encode label\n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(np.ravel(y_train)))\n",
        "y_test = np_utils.to_categorical(lb.transform(np.ravel(y_test)))\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] , X_train.shape[2], X_train.shape[3], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] ,X_test.shape[2], X_test.shape[3], 1)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGAEH8WAtBk1"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXVUsvYntDbw"
      },
      "source": [
        "Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7czDjtAFy8rT"
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "# Define two sets of inputs: MFCC and FBANK\n",
        "input_y = Input(shape=X_train.shape[1:], name='Input_MELSPECT')\n",
        "\n",
        "## First LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_1_MELSPECT')(input_y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_1_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'), name='MaxPool_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_1_MELSPECT')(y)     \n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_2_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_2_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_2_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_3_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_3_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_3_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_4_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_4_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_4_MELSPECT')(y)  \n",
        "\n",
        "## Flat\n",
        "y = TimeDistributed(Flatten(), name='Flat_MELSPECT')(y)                      \n",
        "                               \n",
        "# Apply 2 LSTM layer and one FC\n",
        "y = LSTM(256, return_sequences=False, dropout=0.2, name='LSTM_1')(y)\n",
        "y = Dense(y_train.shape[1], activation='softmax', name='FC')(y)\n",
        "\n",
        "# Build final model\n",
        "model = Model(inputs=input_y, outputs=y)\n",
        "\n",
        "# Plot model graph\n",
        "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "Image(retina=True, filename='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH7slhQRt_hg"
      },
      "source": [
        "Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coiei88Gy64D"
      },
      "source": [
        "# Compile model\n",
        "model.compile(optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.8), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Save best model\n",
        "best_model_save = ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=40, verbose=1, mode='max')\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(X_train,y_train, batch_size=64, epochs=200, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}