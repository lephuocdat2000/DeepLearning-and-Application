{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled156.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/DeepLearning-and-Application/blob/main/Final_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIeQ5xEmxD3n",
        "outputId": "5350caff-5f7c-451d-c35c-4842d9ed3522"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04JWU1uNStHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc259a05-8ac5-493d-ebd1-d1d4e07ae3d9"
      },
      "source": [
        "!pip install simplejpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simplejpeg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/b2/6f2901fb88ada8a43e38483cf7edc207a911b8f18df044398ee9b0e7782d/simplejpeg-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (270kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 24.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 28.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 29.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 30.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 31.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 30.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 30.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 32.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102kB 31.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 112kB 31.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 122kB 31.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 133kB 31.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 31.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 153kB 31.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 163kB 31.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 174kB 31.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 184kB 31.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 194kB 31.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 204kB 31.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 215kB 31.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 225kB 31.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 235kB 31.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 245kB 31.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 256kB 31.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 266kB 31.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 31.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from simplejpeg) (1.19.5)\n",
            "Installing collected packages: simplejpeg\n",
            "Successfully installed simplejpeg-1.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vynViSvIxb0R",
        "outputId": "fc3c7201-950b-48c0-ffc6-7acbfb225cea"
      },
      "source": [
        "# Tạo môi trường để sử dung Yolo\n",
        "!pip install opencv-python==4.4.0.46 -i https://pypi.douban.com/simple"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.douban.com/simple\n",
            "Collecting opencv-python==4.4.0.46\n",
            "\u001b[?25l  Downloading https://pypi.doubanio.com/packages/1b/2d/62eba161d3d713e1720504de1c25d439b02c85159804d9ecead10be5d87e/opencv_python-4.4.0.46-cp37-cp37m-manylinux2014_x86_64.whl (49.5MB)\n",
            "\u001b[K     |████████████████████████████████| 49.5MB 60kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.4.0.46) (1.19.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-4.4.0.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxHDL9-qxdya",
        "outputId": "09749862-710c-4ad8-f8f2-b93c162df1e2"
      },
      "source": [
        "#Thư viện web trên colab\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nJuVUBexNdT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import itertools\n",
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIr1IBp2zwr7"
      },
      "source": [
        "def load_network_1(config_file, data_file, weights, batch_size=1):\n",
        "    \"\"\"\n",
        "    load model description and weights from config files\n",
        "    args:\n",
        "        config_file (str): path to .cfg model file\n",
        "        data_file (str): path to .data model file\n",
        "        weights (str): path to weights\n",
        "    returns:\n",
        "        network: trained model\n",
        "        class_names\n",
        "        class_colors\n",
        "    \"\"\"\n",
        "    network = load_net_custom(\n",
        "        config_file.encode(\"ascii\"),\n",
        "        weights.encode(\"ascii\"), 0, batch_size)\n",
        "    metadata = load_meta(data_file.encode(\"ascii\"))\n",
        "    class_names = [metadata.names[i].decode(\"ascii\") for i in range(1)]\n",
        "    colors = class_colors(class_names)\n",
        "    return network, class_names, colors\n",
        "\n",
        "def darknet_helper(img, width, height):\n",
        "  \"\"\"\n",
        "    predict pedesetrian and return boxes \n",
        "  \"\"\"\n",
        "  darknet_image = make_image(width, height, 3)\n",
        "  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img_resized = cv2.resize(img_rgb, (width, height),\n",
        "                              interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "  # get image ratios to convert bounding boxes to proper size\n",
        "  img_height, img_width, _ = img.shape\n",
        "  width_ratio = img_width/width\n",
        "  height_ratio = img_height/height\n",
        "\n",
        "  # run model on darknet style image to get detections\n",
        "  copy_image_from_bytes(darknet_image, img_resized.tobytes())\n",
        "  detections = detect_image(network, class_names, darknet_image)\n",
        "  free_image(darknet_image)\n",
        "  boxes = np.array([bbox2points(bbox) for _,_,bbox in detections])\n",
        "  boxes = boxes * [width_ratio, height_ratio, width_ratio, height_ratio]\n",
        "  return boxes\n",
        "\n",
        "def MatrixCreation(A,B,C,D):\n",
        "    \"\"\"\n",
        "    Create transformed matrix from 4 points: A,B,C,D \n",
        "    return matrix,width and height of bird-eye-image\n",
        "    \"\"\"\n",
        "    width = int(max(np.sqrt((B[1]-A[1])**2+(B[0]-A[0])**2),np.sqrt((D[1]-C[1])**2+(D[0]-C[0])**2)))\n",
        "    height = int(max(np.sqrt((C[1]-A[1])**2+(C[0]-A[0])**2),np.sqrt((D[1]-B[1])**2+(D[0]-B[0])**2)))\n",
        "    inputs = np.float32([A,B,C,D])\n",
        "    outputs = np.float32([[0,0],\n",
        "                      [width-1,0],\n",
        "                      [0,height-1],\n",
        "                      [width-1,height-1]])\n",
        "    M = cv2.getPerspectiveTransform(inputs,outputs)\n",
        "    return M,width,height\n",
        "\n",
        "def Points_Transformation(boxes):\n",
        "    \"\"\"\n",
        "    Select bottom-center point in boxes and apply perspectiveTransform to points\n",
        "    return transformed_points\n",
        "    \"\"\"\n",
        "    x_ = boxes[:,0]+(boxes[:,2]-boxes[:,0]) / 2\n",
        "    y_ = boxes[:,3]\n",
        "    x_ = np.expand_dims(x_,axis = 1)\n",
        "    y_ = np.expand_dims(y_,axis = 1) \n",
        "    # centroids = np.uint32(np.concatenate((x_,y_),axis=1))\n",
        "    centroids = np.concatenate((x_,y_),axis=1)\n",
        "    list_point_to_detect = centroids.reshape(-1,1,2)\n",
        "    transformed_points = cv2.perspectiveTransform(list_point_to_detect, M)\n",
        "    transformed_points = transformed_points.reshape(transformed_points.shape[0],transformed_points.shape[2])\n",
        "    return transformed_points\n",
        "\n",
        "def DrawnRectangel(boxes,image,point,color):\n",
        "    xmin,ymin,xmax,ymax = boxes[point][:].astype(int)\n",
        "    cv2.rectangle(image,(int(xmin),int(ymin)),(int(xmax),int(ymax)),color,2)  \n",
        "\n",
        "def get_birds_eye_view_image(transformed_points,green_box,red_box,eye_view_height,eye_view_width):\n",
        "    \"\"\"\n",
        "    Create bird_eye_view \n",
        "    \"\"\"\n",
        "    blank_image = cv2.imread('/content/drive/MyDrive/Advanced-CV/black_background.png')\n",
        "    blank_image = cv2.resize(blank_image,(eye_view_width,eye_view_height))\n",
        "    cv2.putText(blank_image, str(len(red_box)), (120,100), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,0,255), 4, cv2.LINE_AA) \n",
        "    cv2.putText(blank_image, str(len(green_box)), (520,100), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,255,0), 4, cv2.LINE_AA)\n",
        "    for point in green_box:\n",
        "        cv2.circle(blank_image,tuple(transformed_points[point].astype(int)),20,(0,255,0),-1)\n",
        "    for point in red_box:\n",
        "        cv2.circle(blank_image,tuple(transformed_points[point].astype(int)),20,(0,0,255),-1)\n",
        "    blank_image = cv2.resize(blank_image,(eye_view_width//2,eye_view_height))\n",
        "    return blank_image\n",
        "     \n",
        "def video_processing(video_path,real_width,real_height,pixel_width,pixel_height):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if (cap.isOpened()==False): \n",
        "        print('Error opening video stream or file')\n",
        "    else: \n",
        "      blank_image = cv2.imread('/content/drive/MyDrive/Advanced-CV/black_background.png')\n",
        "      blank_image = cv2.resize(blank_image,(960,540))\n",
        "      fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "      out = cv2.VideoWriter('output.avi',fourcc, 20, (1440,540))\n",
        "      while (True):\n",
        "          ret, frame = cap.read()\n",
        "          if ret==True:\n",
        "            alter_blank_image = blank_image.copy()\n",
        "            boxes = darknet_helper(frame,width,height)  \n",
        "            transformed_points = Points_Transformation(boxes)\n",
        "            image_rect = frame.copy()\n",
        "            if len(boxes) > 1:  \n",
        "                list_indexes = list(itertools.combinations(range(len(transformed_points)), 2))\n",
        "                x_y_ = []\n",
        "                for i,pair in enumerate(itertools.combinations(transformed_points, r=2)):\n",
        "                     if np.sqrt( ((pair[0][0] - pair[1][0])*real_width/pixel_width)**2 + ((pair[0][1] - pair[1][1])*real_height/pixel_height)**2  ) < int(distance_minimum):\n",
        "                         index_pt1 = list_indexes[i][0]\n",
        "                         index_pt2 = list_indexes[i][1]\n",
        "                         if index_pt1 not in x_y_:\n",
        "                            #draw red circle top view\n",
        "                            cv2.circle(alter_blank_image,tuple(transformed_points[index_pt1].astype(int)),20,(0,0,255),-1)\n",
        "                            #change red box original frame\n",
        "                            DrawnRectangel(boxes,image_rect,index_pt1,(0,0,255))\n",
        "                            x_y_.append(index_pt1)\n",
        "                         if index_pt2 not in x_y_: \n",
        "                            #draw red circle top view    \n",
        "                            cv2.circle(alter_blank_image,tuple(transformed_points[index_pt2].astype(int)),20,(0,0,255),-1)\n",
        "                            #change red box original frame    \n",
        "                            DrawnRectangel(boxes,image_rect,index_pt2,(0,0,255))\n",
        "                            x_y_.append(index_pt2) \n",
        "                #select points to draw green box and green circle \n",
        "                diff = np.setdiff1d(list(range(0,len(boxes))),np.unique(x_y_))\n",
        "                for i in diff:\n",
        "                   DrawnRectangel(boxes,image_rect,i,(0,255,0))\n",
        "                   cv2.circle(alter_blank_image,tuple(transformed_points[i].astype(int)),20,(0,255,0),-1)\n",
        "            elif len(boxes)==1: \n",
        "                 DrawnRectangel(boxes,image_rect,0,(0,255,0))\n",
        "                 cv2.circle(alter_blank_image,tuple(transformed_points[0].astype(int)),20,(0,255,0),-1)\n",
        "            #Write nums of red\n",
        "            height_blank,width_blank = alter_blank_image.shape[0],alter_blank_image.shape[1]\n",
        "            cv2.putText(alter_blank_image, str(len(x_y_)), (int(width_blank*0.225),int(height_blank*0.1)), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,0,255), 4, cv2.LINE_AA) \n",
        "            #Write nums of green\n",
        "            cv2.putText(alter_blank_image, str(len(diff)), (int(width_blank*0.7),int(height_blank*0.1)), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,255,0), 4, cv2.LINE_AA)\n",
        "            alter_blank_image = cv2.resize(alter_blank_image,(alter_blank_image.shape[1]//2,alter_blank_image.shape[0]))\n",
        "            combined_image = np.concatenate((alter_blank_image,image_rect),axis=1)\n",
        "            out.write(combined_image)\n",
        "            if cv2.waitKey(1)==ord('q'): break\n",
        "          else: break \n",
        "    out.release()\n",
        "    return\n",
        "def show_webcam(mirror=False):\n",
        "    vid = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "       ret,frame = vid.read()\n",
        "       plt.imshow('frame',frame)\n",
        "       if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "    vid.release()\n",
        "    cv2.destroyAllWindows() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsXCZbjgx0yH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cbfc48-606f-447c-c41b-7f5cb11f000e"
      },
      "source": [
        "%cd /content/drive/MyDrive/darknet\n",
        "#608X608\n",
        "# load in our YOLOv4 architecture network\n",
        "from darknet import *\n",
        "network, class_names, class_colors = load_network_1(\"cfg/yolov4.cfg\", \"cfg/coco.data\", \"yolov4.weights\")\n",
        "width = network_width(network)\n",
        "height = network_height(network)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/darknet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2uCfAhC1Gjc",
        "outputId": "b3a4b278-8dff-4c69-dcb7-07c552f210d5"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, jsonify, render_template,Response\n",
        "import sys\n",
        "from imutils.video import FileVideoStream\n",
        "import simplejpeg\n",
        "\n",
        "app = Flask(__name__,template_folder=\"/content/templates\")\n",
        "run_with_ngrok(app)\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "@app.route('/detectObject' , methods=['POST'])\n",
        "def mask_image():\n",
        "\tfile = request.files['image'] ## byte file\n",
        "\tfile.save(\"/content/data.avi\")\n",
        "\tvideo=cv2.VideoCapture(\"/content/data.avi\")\n",
        "\tret,frame=video.read()\n",
        "\tif not ret:\n",
        "\t\treturn jsonify({'error':True})\n",
        "\treturn jsonify({'success':True})\n",
        "####################### MONITOR SOCIAL DISTANCE ############################\n",
        "image_height=540\n",
        "image_width=960\n",
        "#4 points ROI\n",
        "A = [571,151]\n",
        "B = [768,185]\n",
        "C = [283,400]\n",
        "D = [690,521]\n",
        "M,pixel_width,pixel_height = MatrixCreation(A,B,C,D)\n",
        "real_width,real_height = 4.0,7.6\n",
        "distance_minimum = 2.0\n",
        "\n",
        "def gen():\n",
        "    frame_number = 0\n",
        "    video = cv2.VideoCapture('/content/data.avi')\n",
        "    min_distance=200\n",
        "    #blank_image is background of bird-eye-view\n",
        "    blank_image = cv2.imread('/content/black_background.png')\n",
        "    blank_image = cv2.resize(blank_image,(pixel_width,pixel_height))\n",
        "    while True:\n",
        "        ret,frame = video.read()\n",
        "        if not ret:\n",
        "          break\n",
        "        #Phát hiện người\n",
        "        alter_blank_image = blank_image.copy()\n",
        "        #Predict boxes\n",
        "        boxes = darknet_helper(frame,width,height) \n",
        "        # Transform bottom-center points \n",
        "        transformed_points = Points_Transformation(boxes)\n",
        "        image_rect = frame.copy()\n",
        "        # Calculate distance and drawn rectangle, circle\n",
        "        if len(boxes) > 1:  \n",
        "            list_indexes = list(itertools.combinations(range(len(transformed_points)), 2))\n",
        "            x_y_ = []\n",
        "            for i,pair in enumerate(itertools.combinations(transformed_points, r=2)):\n",
        "               if np.sqrt( ((pair[0][0] - pair[1][0])*real_width/pixel_width)**2 + ((pair[0][1] - pair[1][1])*real_height/pixel_height)**2  ) < int(distance_minimum):\n",
        "                  index_pt1 = list_indexes[i][0]\n",
        "                  index_pt2 = list_indexes[i][1]\n",
        "                  if index_pt1 not in x_y_:\n",
        "                     #draw red circle top view\n",
        "                     cv2.circle(alter_blank_image,tuple(transformed_points[index_pt1].astype(int)),20,(0,0,255),-1)\n",
        "                     #change red box original frame\n",
        "                     DrawnRectangel(boxes,image_rect,index_pt1,(0,0,255))\n",
        "                     x_y_.append(index_pt1)\n",
        "                  if index_pt2 not in x_y_: \n",
        "                     #draw red circle top view    \n",
        "                     cv2.circle(alter_blank_image,tuple(transformed_points[index_pt2].astype(int)),20,(0,0,255),-1)\n",
        "                     #change red box original frame    \n",
        "                     DrawnRectangel(boxes,image_rect,index_pt2,(0,0,255))\n",
        "                     x_y_.append(index_pt2) \n",
        "               #select points to draw green box and green circle \n",
        "               diff = np.setdiff1d(list(range(0,len(boxes))),np.unique(x_y_))\n",
        "               for i in diff:\n",
        "                   DrawnRectangel(boxes,image_rect,i,(0,255,0))\n",
        "                   cv2.circle(alter_blank_image,tuple(transformed_points[i].astype(int)),20,(0,255,0),-1)\n",
        "        elif len(boxes)==1: \n",
        "            DrawnRectangel(boxes,image_rect,0,(0,255,0))\n",
        "            cv2.circle(alter_blank_image,tuple(transformed_points[0].astype(int)),20,(0,255,0),-1)\n",
        "        #Write nums of red\n",
        "        height_blank,width_blank = alter_blank_image.shape[0],alter_blank_image.shape[1]\n",
        "        cv2.putText(alter_blank_image, str(len(x_y_)), (int(width_blank*0.225),int(height_blank*0.1)), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,0,255), 4, cv2.LINE_AA) \n",
        "        #Write nums of green\n",
        "        cv2.putText(alter_blank_image, str(len(diff)), (int(width_blank*0.7),int(height_blank*0.1)), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,255,0), 4, cv2.LINE_AA)\n",
        "        alter_blank_image = cv2.resize(alter_blank_image,(image_width//2,image_height))\n",
        "        combined_image = np.concatenate((alter_blank_image,image_rect),axis=1)\n",
        "        frame=simplejpeg.encode_jpeg(image=combined_image,quality=70,colorspace='BGR',colorsubsampling='444', fastdct=True)\n",
        "        yield (b'--frame\\r\\n'b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
        "        del boxes,alter_blank_image,diff,x_y_,combined_image\n",
        "        key = cv2.waitKey(5)\n",
        "        if key == 30:\n",
        "          break\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "\treturn Response(gen(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://d04e576db121.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [23/Jun/2021 10:02:20] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Jun/2021 10:02:21] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [23/Jun/2021 10:02:22] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Jun/2021 10:02:35] \"\u001b[37mPOST /detectObject HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Jun/2021 10:02:35] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}