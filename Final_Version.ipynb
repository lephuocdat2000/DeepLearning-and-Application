{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled156.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/DeepLearning-and-Application/blob/main/Final_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIeQ5xEmxD3n",
        "outputId": "41bf296d-e47f-4388-85e9-2b96fd3f8338"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vynViSvIxb0R",
        "outputId": "2c1c8e02-228e-4a4d-b901-a8c576bb3ff6"
      },
      "source": [
        "# Tạo môi trường để sử dung Yolo\n",
        "!pip install opencv-python==4.4.0.46 -i https://pypi.douban.com/simple"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.douban.com/simple\n",
            "Requirement already satisfied: opencv-python==4.4.0.46 in /usr/local/lib/python3.7/dist-packages (4.4.0.46)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.4.0.46) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxHDL9-qxdya",
        "outputId": "4426eb97-afb4-417e-b267-f53bc5800a5e"
      },
      "source": [
        "#Thư viện web trên colab\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nJuVUBexNdT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "import itertools\n",
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIr1IBp2zwr7"
      },
      "source": [
        "def load_network_1(config_file, data_file, weights, batch_size=1):\n",
        "    \"\"\"\n",
        "    load model description and weights from config files\n",
        "    args:\n",
        "        config_file (str): path to .cfg model file\n",
        "        data_file (str): path to .data model file\n",
        "        weights (str): path to weights\n",
        "    returns:\n",
        "        network: trained model\n",
        "        class_names\n",
        "        class_colors\n",
        "    \"\"\"\n",
        "    network = load_net_custom(\n",
        "        config_file.encode(\"ascii\"),\n",
        "        weights.encode(\"ascii\"), 0, batch_size)\n",
        "    metadata = load_meta(data_file.encode(\"ascii\"))\n",
        "    class_names = [metadata.names[i].decode(\"ascii\") for i in range(1)]\n",
        "    colors = class_colors(class_names)\n",
        "    return network, class_names, colors\n",
        "\n",
        "def darknet_helper(img, width, height):\n",
        "  darknet_image = make_image(width, height, 3)\n",
        "  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img_resized = cv2.resize(img_rgb, (width, height),\n",
        "                              interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "  # get image ratios to convert bounding boxes to proper size\n",
        "  img_height, img_width, _ = img.shape\n",
        "  width_ratio = img_width/width\n",
        "  height_ratio = img_height/height\n",
        "\n",
        "  # run model on darknet style image to get detections\n",
        "  copy_image_from_bytes(darknet_image, img_resized.tobytes())\n",
        "  detections = detect_image(network, class_names, darknet_image)\n",
        "  free_image(darknet_image)\n",
        "  boxes = np.array([bbox2points(bbox) for _,_,bbox in detections])\n",
        "  boxes = boxes * [width_ratio, height_ratio, width_ratio, height_ratio]\n",
        "  return boxes\n",
        "\n",
        "def MatrixCreation(A,B,C,D):\n",
        "    width = int(max(np.sqrt((B[1]-A[1])**2+(B[0]-A[0])**2),np.sqrt((D[1]-C[1])**2+(D[0]-C[0])**2)))\n",
        "    height = int(max(np.sqrt((C[1]-A[1])**2+(C[0]-A[0])**2),np.sqrt((D[1]-B[1])**2+(D[0]-B[0])**2)))\n",
        "    inputs = np.float32([A,B,C,D])\n",
        "    outputs = np.float32([[0,0],\n",
        "                      [width-1,0],\n",
        "                      [0,height-1],\n",
        "                      [width-1,height-1]])\n",
        "    M = cv2.getPerspectiveTransform(inputs,outputs)\n",
        "    return M,width,height\n",
        "\n",
        "def Points_Transformation(boxes):\n",
        "    x_ = boxes[:,0]+(boxes[:,2]-boxes[:,0]) / 2\n",
        "    # y_ = boxes[:,1]+(boxes[:,3]-boxes[:,1]) / 2\n",
        "    y_ = boxes[:,3]\n",
        "    x_ = np.expand_dims(x_,axis = 1)\n",
        "    y_ = np.expand_dims(y_,axis = 1) \n",
        "    # centroids = np.uint32(np.concatenate((x_,y_),axis=1))\n",
        "    centroids = np.concatenate((x_,y_),axis=1)\n",
        "    list_point_to_detect = centroids.reshape(-1,1,2)\n",
        "    transformed_points = cv2.perspectiveTransform(list_point_to_detect, M)\n",
        "    transformed_points = transformed_points.reshape(transformed_points.shape[0],transformed_points.shape[2])\n",
        "    return transformed_points\n",
        "\n",
        "def DrawnRectangel(boxes,image,point,color):\n",
        "    # xmin,ymin,xmax,ymax = int(boxes[point][0]),int(boxes[point][1]),int(boxes[point][2]),int(boxes[point][3])\n",
        "    xmin,ymin,xmax,ymax = boxes[point][:].astype(int)\n",
        "    cv2.rectangle(image,(int(xmin),int(ymin)),(int(xmax),int(ymax)),color,2)  \n",
        "\n",
        "def get_birds_eye_view_image(transformed_points,green_box,red_box,eye_view_height,eye_view_width):\n",
        "    blank_image = cv2.imread('/content/drive/MyDrive/Advanced-CV/black_background.png')\n",
        "    blank_image = cv2.resize(blank_image,(eye_view_width,eye_view_height))\n",
        "    cv2.putText(blank_image, str(len(red_box)), (120,100), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,0,255), 4, cv2.LINE_AA) \n",
        "    cv2.putText(blank_image, str(len(green_box)), (520,100), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,255,0), 4, cv2.LINE_AA)\n",
        "    for point in green_box:\n",
        "        cv2.circle(blank_image,tuple(transformed_points[point].astype(int)),20,(0,255,0),-1)\n",
        "    for point in red_box:\n",
        "        cv2.circle(blank_image,tuple(transformed_points[point].astype(int)),20,(0,0,255),-1)\n",
        "    blank_image = cv2.resize(blank_image,(eye_view_width//2,eye_view_height))\n",
        "    return blank_image\n",
        "     \n",
        "def video_processing(video_path,real_width,real_height,pixel_width,pixel_height):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if (cap.isOpened()==False): \n",
        "        print('Error opening video stream or file')\n",
        "    else: \n",
        "      blank_image = cv2.imread('/content/drive/MyDrive/Advanced-CV/black_background.png')\n",
        "      blank_image = cv2.resize(blank_image,(960,540))\n",
        "      fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "      out = cv2.VideoWriter('output.avi',fourcc, 20, (1440,540))\n",
        "      while (True):\n",
        "          ret, frame = cap.read()\n",
        "          if ret==True:\n",
        "            alter_blank_image = blank_image.copy()\n",
        "            boxes = darknet_helper(frame,width,height)  \n",
        "            transformed_points = Points_Transformation(boxes)\n",
        "            image_rect = frame.copy()\n",
        "            if len(boxes) > 1:  \n",
        "                list_indexes = list(itertools.combinations(range(len(transformed_points)), 2))\n",
        "                x_y_ = []\n",
        "                for i,pair in enumerate(itertools.combinations(transformed_points, r=2)):\n",
        "                     if np.sqrt( ((pair[0][0] - pair[1][0])*real_width/pixel_width)**2 + ((pair[0][1] - pair[1][1])*real_height/pixel_height)**2  ) < int(distance_minimum):\n",
        "                         index_pt1 = list_indexes[i][0]\n",
        "                         index_pt2 = list_indexes[i][1]\n",
        "                         if index_pt1 not in x_y_:\n",
        "                            #draw red circle top view\n",
        "                            cv2.circle(alter_blank_image,tuple(transformed_points[index_pt1].astype(int)),20,(0,0,255),-1)\n",
        "                            #change red box original frame\n",
        "                            DrawnRectangel(boxes,image_rect,index_pt1,(0,0,255))\n",
        "                            x_y_.append(index_pt1)\n",
        "                         if index_pt2 not in x_y_: \n",
        "                            #draw red circle top view    \n",
        "                            cv2.circle(alter_blank_image,tuple(transformed_points[index_pt2].astype(int)),20,(0,0,255),-1)\n",
        "                            #change red box original frame    \n",
        "                            DrawnRectangel(boxes,image_rect,index_pt2,(0,0,255))\n",
        "                            x_y_.append(index_pt2) \n",
        "                #select points to draw green box and green circle \n",
        "                diff = np.setdiff1d(list(range(0,len(boxes))),np.unique(x_y_))\n",
        "                for i in diff:\n",
        "                   DrawnRectangel(boxes,image_rect,i,(0,255,0))\n",
        "                   cv2.circle(alter_blank_image,tuple(transformed_points[i].astype(int)),20,(0,255,0),-1)\n",
        "            elif len(boxes)==1: \n",
        "                 DrawnRectangel(boxes,image_rect,0,(0,255,0))\n",
        "                 cv2.circle(alter_blank_image,tuple(transformed_points[0].astype(int)),20,(0,255,0),-1)\n",
        "            #Write nums of red\n",
        "            height_blank,width_blank = alter_blank_image.shape[0],alter_blank_image.shape[1]\n",
        "            cv2.putText(alter_blank_image, str(len(x_y_)), (int(width_blank*0.225),int(height_blank*0.1)), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,0,255), 4, cv2.LINE_AA) \n",
        "            #Write nums of green\n",
        "            cv2.putText(alter_blank_image, str(len(diff)), (int(width_blank*0.7),int(height_blank*0.1)), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,255,0), 4, cv2.LINE_AA)\n",
        "            alter_blank_image = cv2.resize(alter_blank_image,(alter_blank_image.shape[1]//2,alter_blank_image.shape[0]))\n",
        "            combined_image = np.concatenate((alter_blank_image,image_rect),axis=1)\n",
        "            out.write(combined_image)\n",
        "            if cv2.waitKey(1)==ord('q'): break\n",
        "          else: break \n",
        "    out.release()\n",
        "    return\n",
        "def show_webcam(mirror=False):\n",
        "    vid = cv2.VideoCapture(0)\n",
        "    while True:\n",
        "       ret,frame = vid.read()\n",
        "       plt.imshow('frame',frame)\n",
        "       if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "    vid.release()\n",
        "    cv2.destroyAllWindows() \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsXCZbjgx0yH",
        "outputId": "65eeb283-a620-4309-f098-4545e7dd22e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/MyDrive/darknet\n",
        "#608X608\n",
        "# load in our YOLOv4 architecture network\n",
        "from darknet import *\n",
        "network, class_names, class_colors = load_network_1(\"cfg/yolov4.cfg\", \"cfg/coco.data\", \"yolov4.weights\")\n",
        "width = network_width(network)\n",
        "height = network_height(network)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/darknet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2uCfAhC1Gjc",
        "outputId": "53290d8f-d8c7-477b-f8e0-7501116c47e5"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, jsonify, render_template,Response\n",
        "import sys\n",
        "from imutils.video import FileVideoStream\n",
        "app = Flask(__name__,template_folder=\"/content/templates\")\n",
        "run_with_ngrok(app)\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "@app.route('/detectObject' , methods=['POST'])\n",
        "def mask_image():\n",
        "\tfile = request.files['image'] ## byte file\n",
        "\tfile.save(\"/content/data.avi\")\n",
        "\tvideo=cv2.VideoCapture(\"/content/data.avi\")\n",
        "\tret,frame=video.read()\n",
        "\tif not ret:\n",
        "\t\treturn jsonify({'error':True})\n",
        "\treturn jsonify({'success':True})\n",
        "####################### MONITOR SOCIAL DISTANCE ############################\n",
        "image_height=540\n",
        "image_width=960\n",
        "A = [571,151]\n",
        "B = [768,185]\n",
        "C = [283,400]\n",
        "D = [690,521]\n",
        "M,pixel_width,pixel_height = MatrixCreation(A,B,C,D)\n",
        "real_width,real_height = 4.0,7.6\n",
        "distance_minimum = 2.0\n",
        "\n",
        "def gen():\n",
        "    frame_number = 0\n",
        "    video = cv2.VideoCapture('/content/data.avi')\n",
        "    min_distance=200\n",
        "    blank_image = cv2.imread('/content/black_background.png')\n",
        "    blank_image = cv2.resize(blank_image,(pixel_width,pixel_height))\n",
        "    while True:\n",
        "        ret,frame = video.read()\n",
        "        if not ret:\n",
        "          break\n",
        "        #Phát hiện người\n",
        "        alter_blank_image = blank_image.copy()\n",
        "        boxes = darknet_helper(frame,width,height)  \n",
        "        transformed_points = Points_Transformation(boxes)\n",
        "        image_rect = frame.copy()\n",
        "        if len(boxes) > 1:  \n",
        "            list_indexes = list(itertools.combinations(range(len(transformed_points)), 2))\n",
        "            x_y_ = []\n",
        "            for i,pair in enumerate(itertools.combinations(transformed_points, r=2)):\n",
        "               if np.sqrt( ((pair[0][0] - pair[1][0])*real_width/pixel_width)**2 + ((pair[0][1] - pair[1][1])*real_height/pixel_height)**2  ) < int(distance_minimum):\n",
        "                  index_pt1 = list_indexes[i][0]\n",
        "                  index_pt2 = list_indexes[i][1]\n",
        "                  if index_pt1 not in x_y_:\n",
        "                     #draw red circle top view\n",
        "                     cv2.circle(alter_blank_image,tuple(transformed_points[index_pt1].astype(int)),20,(0,0,255),-1)\n",
        "                     #change red box original frame\n",
        "                     DrawnRectangel(boxes,image_rect,index_pt1,(0,0,255))\n",
        "                     x_y_.append(index_pt1)\n",
        "                  if index_pt2 not in x_y_: \n",
        "                     #draw red circle top view    \n",
        "                     cv2.circle(alter_blank_image,tuple(transformed_points[index_pt2].astype(int)),20,(0,0,255),-1)\n",
        "                     #change red box original frame    \n",
        "                     DrawnRectangel(boxes,image_rect,index_pt2,(0,0,255))\n",
        "                     x_y_.append(index_pt2) \n",
        "               #select points to draw green box and green circle \n",
        "               diff = np.setdiff1d(list(range(0,len(boxes))),np.unique(x_y_))\n",
        "               for i in diff:\n",
        "                   DrawnRectangel(boxes,image_rect,i,(0,255,0))\n",
        "                   cv2.circle(alter_blank_image,tuple(transformed_points[i].astype(int)),20,(0,255,0),-1)\n",
        "        elif len(boxes)==1: \n",
        "            DrawnRectangel(boxes,image_rect,0,(0,255,0))\n",
        "            cv2.circle(alter_blank_image,tuple(transformed_points[0].astype(int)),20,(0,255,0),-1)\n",
        "        #Write nums of red\n",
        "        height_blank,width_blank = alter_blank_image.shape[0],alter_blank_image.shape[1]\n",
        "        cv2.putText(alter_blank_image, str(len(x_y_)), (int(width_blank*0.225),int(height_blank*0.1)), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,0,255), 4, cv2.LINE_AA) \n",
        "        #Write nums of green\n",
        "        cv2.putText(alter_blank_image, str(len(diff)), (int(width_blank*0.7),int(height_blank*0.1)), cv2.FONT_HERSHEY_SIMPLEX , 2, (0,255,0), 4, cv2.LINE_AA)\n",
        "        alter_blank_image = cv2.resize(alter_blank_image,(image_width//2,image_height))\n",
        "        combined_image = np.concatenate((alter_blank_image,image_rect),axis=1)\n",
        "        frame = cv2.imencode('.jpg', combined_image)[1].tobytes()\n",
        "        yield (b'--frame\\r\\n'b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
        "        del boxes,alter_blank_image,diff,x_y_,combined_image\n",
        "        key = cv2.waitKey(5)\n",
        "        if key == 30:\n",
        "          break\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "\treturn Response(gen(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "app.run()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://10fef0870730.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [23/Jun/2021 09:03:14] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Jun/2021 09:03:15] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [23/Jun/2021 09:03:16] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Jun/2021 09:03:27] \"\u001b[37mPOST /detectObject HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [23/Jun/2021 09:03:28] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}