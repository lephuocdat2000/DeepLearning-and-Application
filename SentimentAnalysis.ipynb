{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled154.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSM2Z31h6sg90pSm+U9Usz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/DeepLearning-and-Application/blob/main/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kny9f6G9z3u",
        "outputId": "09ee3a7c-cd0a-49a8-992c-195fb9759932"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfL_XLtf0dp6"
      },
      "source": [
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEWfJdFz0nJR"
      },
      "source": [
        "#Load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWWzyM9t0t4V"
      },
      "source": [
        "Tải pretrained model cho Tiếng Việt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whMfGeW-1GWh",
        "outputId": "6307003c-0ce5-4e5b-da44-f63ec52708ad"
      },
      "source": [
        "!pip install fasttext\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "  Using cached https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3096966 sha256=e34062d73b0465b928102841107a3593fbbf0056f9e8611f7eafe78cfb2127f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os5g68_m0lip"
      },
      "source": [
        "import fasttext.util\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ublYBO6xxWv"
      },
      "source": [
        "fasttext.util.download_model('vi',if_exists='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFP6xB76_KS7"
      },
      "source": [
        "Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzLLV5dV_Jo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664efd47-118c-44c3-98e0-7381c309d739"
      },
      "source": [
        "ft = fasttext.load_model('/content/drive/MyDrive/DeepLearning_Application/Lab3-Word2Vec-With-Pretrained-Model/cc.vi.300.bin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCw2Epf5A-kS",
        "outputId": "c028674d-0ced-480a-b789-8576921181f1"
      },
      "source": [
        "%cd /content/drive/MyDrive/DeepLearning_Application/Assignment3-SentimentAnalysis-with-LSTM/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/DeepLearning_Application/Assignment3-SentimentAnalysis-with-LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dewg4JU_VBk"
      },
      "source": [
        "#Load tập từ vựng và ma trận word-embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKkqOk10zGJo",
        "outputId": "50bbb4eb-3141-4ab4-be6e-bf4d4a635586"
      },
      "source": [
        "currentDir = '/content/drive/MyDrive/DeepLearning_Application/Assignment3-SentimentAnalysis-with-LSTM/'\n",
        "wordsList = np.load(os.path.join(currentDir, 'wordsList.npy'))\n",
        "print('Simplified vocabulary loaded!')\n",
        "wordsList = wordsList.tolist()\n",
        "\n",
        "wordVectors = np.load(os.path.join(currentDir, 'wordVectors.npy'))\n",
        "wordVectors = np.float32(wordVectors)\n",
        "print ('Word embedding matrix loaded!')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simplified vocabulary loaded!\n",
            "Word embedding matrix loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4lEok-wJ6Bd",
        "outputId": "6dd367c6-81ab-4ec1-8418-cb2744f23b15"
      },
      "source": [
        "print('Size of the vocabulary: ', len(wordsList))\n",
        "print('Size of the word embedding matrix: ', wordVectors.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the vocabulary:  19899\n",
            "Size of the word embedding matrix:  (19899, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFdV1Ab2KB98",
        "outputId": "6ec3c1b7-9eb1-4470-fb9e-82cac538b21e"
      },
      "source": [
        "import tensorflow as tf\n",
        "maxSeqLength = 10   #Maximum length of sentence\n",
        "numDimensions = 300 #Dimensions for each word vector\n",
        "sentenceIndexes = np.zeros((maxSeqLength), dtype='int32')\n",
        "\n",
        "# TODO 3.1: Gán chỉ số của các từ trong câu và 'sentenceIndexes'\n",
        "sentence = 'Món này ăn hoài không hề biết chán'\n",
        "words = sentence.split(\" \")\n",
        "for index,word in enumerate(words):\n",
        "    word_idx = wordsList.index(word.lower())\n",
        "    sentenceIndexes[index]=word_idx\n",
        "print(sentenceIndexes)\n",
        "#  Ma trận biểu diễn:\n",
        "print('Sentence representation of word vectors:')\n",
        "print(tf.nn.embedding_lookup(wordVectors,sentenceIndexes))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  119  8136  4884 18791 16614 12231 15951  3371     0     0]\n",
            "Sentence representation of word vectors:\n",
            "tf.Tensor(\n",
            "[[-0.1823 -0.0638  0.2376 ...  0.1462 -0.1092  0.0137]\n",
            " [ 0.027  -0.0542  0.1437 ... -0.0913  0.0114  0.0132]\n",
            " [ 0.021   0.0102  0.0096 ...  0.411  -0.2519  0.0151]\n",
            " ...\n",
            " [-0.0239 -0.0383  0.1734 ... -0.0677 -0.096   0.0045]\n",
            " [ 0.1882 -0.292   0.0072 ...  0.5919 -0.3094 -0.1228]\n",
            " [ 0.1882 -0.292   0.0072 ...  0.5919 -0.3094 -0.1228]], shape=(10, 300), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8l9RydNXOv-"
      },
      "source": [
        "Visual Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of9NeGNNEPkQ"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "positiveFiles = ['positiveReviews/' + f for f in listdir('positiveReviews/') if isfile(join('positiveReviews/', f))]\n",
        "negativeFiles = ['negativeReviews/' + f for f in listdir('negativeReviews/') if isfile(join('negativeReviews/', f))]\n",
        "numWords = []\n",
        "for pf in positiveFiles:\n",
        "    with open(pf, \"r\", encoding='utf-8') as f:\n",
        "        line=f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)       \n",
        "print('Positive files finished')\n",
        "\n",
        "for nf in negativeFiles:\n",
        "    with open(nf, \"r\", encoding='utf-8') as f:\n",
        "        line=f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)  \n",
        "print('Negative files finished')\n",
        "\n",
        "numFiles = len(numWords)\n",
        "print('The total number of files is', numFiles)\n",
        "print('The total number of words in the files is', sum(numWords))\n",
        "print('The average number of words in the files is', sum(numWords)/len(numWords))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTFncENuSbzM"
      },
      "source": [
        "#Chuẩn hóa văn bản và tách từ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Tm8CVQSe4-"
      },
      "source": [
        "import re\n",
        "strip_special_chars = re.compile(\"[^\\w0-9 ]+\")\n",
        "\n",
        "def cleanSentences(string):\n",
        "    string = string.lower().replace(\"<br />\", \" \")\n",
        "    return re.sub(strip_special_chars, \"\", string.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGl2censlK6T"
      },
      "source": [
        "maxSeqLength = 180"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUPYU5SqHh0m"
      },
      "source": [
        "Chạy và lưu vào file idsMatrix.npy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4GwFonIHb_I"
      },
      "source": [
        "ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
        "nFiles = 0\n",
        "# Index of Unknow word\n",
        "unk_idx = wordsList.index('UNK')\n",
        "\n",
        "for pf in positiveFiles:\n",
        "    with open(pf, \"r\", encoding=\"utf-8\") as f:\n",
        "        nIndexes = 0\n",
        "        line=f.readline()\n",
        "        cleanedLine = cleanSentences(line)\n",
        "        split = cleanedLine.split()\n",
        "        for word in split:\n",
        "            # TODO 3.2: Nếu 'word' thuộc tập 'wordsList' thì gán chỉ số của 'word' vào ma trận ids\n",
        "            if word in wordsList:\n",
        "               word_idx = wordsList.index(word)\n",
        "               ids[nFiles][word_idx] = word_idx\n",
        "            # Ngược lại: gán 'unk_idx' vào ma trận ids\n",
        "            nIndexes = nIndexes + 1\n",
        "            if nIndexes >= maxSeqLength:\n",
        "                break\n",
        "        nFiles = nFiles + 1 \n",
        "\n",
        "print('Positive files are indexed!')\n",
        "for nf in negativeFiles:\n",
        "    with open(nf, \"r\", encoding=\"utf-8\") as f:\n",
        "        nIndexes = 0\n",
        "        line=f.readline()\n",
        "        cleanedLine = cleanSentences(line)\n",
        "        split = cleanedLine.split()\n",
        "        for word in split:\n",
        "            # ToDo 3.2: tương tự như trên. Không khác gì hết.\n",
        "            if word in wordsList:\n",
        "               word_idx = wordsList.index(word)\n",
        "               ids[nFiles][word_idx] = word_idx\n",
        "            nIndexes = nIndexes + 1\n",
        "            if nIndexes >= maxSeqLength:\n",
        "                break\n",
        "        nFiles = nFiles + 1 \n",
        "\n",
        "print('Negative files are indexed!')\n",
        "# Save ids Matrix for future uses.\n",
        "np.save(os.path.join(currentDir,'idsMatrix.npy'), ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOlq85klHmeW"
      },
      "source": [
        "Load file đã chạy để tiết kiệm thời gian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wF-oViLHhHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d57104f-b83d-4b73-cc83-6b3973aaa848"
      },
      "source": [
        "ids = np.load(os.path.join(currentDir,'idsMatrix.npy'))\n",
        "print('Word indexes of the first review: ', ids[0])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word indexes of the first review:  [19898  1906  4454  5284 10661 11694 11994 18784 18569 18619 13174  9821\n",
            " 14794  8884  6443  5767  8589 18850 15570  5596   799 11060  4222 16893\n",
            " 13078  8136  3364  4454  4756 10304  8885  3553  9782  1232 14359 10606\n",
            "   579 15522  2219 15092 14855 15253  4884  3364  5519  4558  9649   269\n",
            " 15522 12309 14855 11503  2212  4884  7155 11577  4222  5767 15076 12225\n",
            " 10774  1218  2876 19584  4558  2974 13452  5013   842 10642 17292 11895\n",
            "   803 11060 16760  1906 15253 14598 15253  1047  5668  4884 10642 12225\n",
            "  7090 17292 18109 13078 16334  1238  3364  5519  4135  3553 14967  4964\n",
            " 15385  9673  2997 14855  7446  8038 11440  1345   842  5767   803 11060\n",
            " 18791  5013     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiJJrXZ0HzCU"
      },
      "source": [
        "#Xây dựng hàm lấy dữ liệu train và test theo từng batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhU1tmIFH3wb"
      },
      "source": [
        "from random import randint\n",
        "\n",
        "def getTrainBatch():\n",
        "    labels = []\n",
        "    arr = np.zeros([batchSize, maxSeqLength])\n",
        "    for i in range(batchSize):\n",
        "        if (i % 2 == 0): \n",
        "            # Pick positive samples randomly\n",
        "            num = randint(1,13999)\n",
        "            labels.append([1,0])\n",
        "        else:\n",
        "            # Pick negative samples randomly\n",
        "            num = randint(15999,29999)\n",
        "            labels.append([0,1])\n",
        "        arr[i] = ids[num-1:num]\n",
        "    return arr, labels\n",
        "\n",
        "def getTestBatch():\n",
        "    labels = []\n",
        "    arr = np.zeros([batchSize, maxSeqLength])\n",
        "    for i in range(batchSize):\n",
        "        num = randint(13999,15999)\n",
        "        if (num <= 14999):\n",
        "            labels.append([1,0])\n",
        "        else:\n",
        "            labels.append([0,1])\n",
        "        arr[i] = ids[num-1:num]\n",
        "    return arr, labels"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOxapFE6JXxG"
      },
      "source": [
        "#3.Xây dựng RNN Model với Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LjY8o0bJcmJ"
      },
      "source": [
        "# Initialize paramters\n",
        "numDimensions = 300\n",
        "batchSize = 64\n",
        "lstmUnits = 128\n",
        "nLayers = 2\n",
        "numClasses = 2\n",
        "iterations = 30000"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4zqjkEWKp6r"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = ids.copy()\n",
        "Y = np.concatenate((np.ones((15000,1)),np.zeros((15000,1))))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.067)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ8DhdnhLgkU"
      },
      "source": [
        "# Create a callback that saves the model's weights\n",
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "model = keras.Sequential([\n",
        "        layers.Embedding(input_dim=19899,output_dim=numDimensions,weights=[wordVectors],input_length=maxSeqLength,trainable=False),\n",
        "        layers.LSTM(lstmUnits,return_sequences=True),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.LSTM(lstmUnits),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(2,activation='softmax')]\n",
        " )\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='Adam',\n",
        "    metrics=[\"accuracy\"])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M3oCiZTc98E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1738b0-2eed-4240-f052-e98a8a66cc8f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 180, 300)          5969700   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 180, 128)          219648    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 180, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 6,321,190\n",
            "Trainable params: 351,490\n",
            "Non-trainable params: 5,969,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkYzXa-OnSKM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d84b87ea-c45b-427e-bf0b-1a8b54021d54"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batchSize, epochs=30000,callbacks=[cp_callback])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "438/438 [==============================] - 19s 37ms/step - loss: 0.6938 - accuracy: 0.5064 - val_loss: 0.6901 - val_accuracy: 0.5002\n",
            "\n",
            "Epoch 00001: saving model to training_2/cp-0001.ckpt\n",
            "Epoch 2/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.6919 - accuracy: 0.5074 - val_loss: 0.6898 - val_accuracy: 0.5132\n",
            "\n",
            "Epoch 00002: saving model to training_2/cp-0002.ckpt\n",
            "Epoch 3/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.6921 - accuracy: 0.5031 - val_loss: 0.6903 - val_accuracy: 0.5062\n",
            "\n",
            "Epoch 00003: saving model to training_2/cp-0003.ckpt\n",
            "Epoch 4/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.6919 - accuracy: 0.5054 - val_loss: 0.6894 - val_accuracy: 0.5067\n",
            "\n",
            "Epoch 00004: saving model to training_2/cp-0004.ckpt\n",
            "Epoch 5/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.6917 - accuracy: 0.5125 - val_loss: 0.6897 - val_accuracy: 0.5132\n",
            "\n",
            "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
            "Epoch 6/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.6915 - accuracy: 0.5095 - val_loss: 0.6898 - val_accuracy: 0.5067\n",
            "\n",
            "Epoch 00006: saving model to training_2/cp-0006.ckpt\n",
            "Epoch 7/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.6912 - accuracy: 0.5182 - val_loss: 0.6962 - val_accuracy: 0.5694\n",
            "\n",
            "Epoch 00007: saving model to training_2/cp-0007.ckpt\n",
            "Epoch 8/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.5159 - accuracy: 0.7463 - val_loss: 0.4377 - val_accuracy: 0.7862\n",
            "\n",
            "Epoch 00008: saving model to training_2/cp-0008.ckpt\n",
            "Epoch 9/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.4194 - val_accuracy: 0.8026\n",
            "\n",
            "Epoch 00009: saving model to training_2/cp-0009.ckpt\n",
            "Epoch 10/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.3980 - accuracy: 0.8172 - val_loss: 0.4045 - val_accuracy: 0.8130\n",
            "\n",
            "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
            "Epoch 11/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.3789 - accuracy: 0.8289 - val_loss: 0.4218 - val_accuracy: 0.8031\n",
            "\n",
            "Epoch 00011: saving model to training_2/cp-0011.ckpt\n",
            "Epoch 12/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.3611 - accuracy: 0.8363 - val_loss: 0.3810 - val_accuracy: 0.8225\n",
            "\n",
            "Epoch 00012: saving model to training_2/cp-0012.ckpt\n",
            "Epoch 13/30000\n",
            "438/438 [==============================] - 16s 35ms/step - loss: 0.3462 - accuracy: 0.8455 - val_loss: 0.3846 - val_accuracy: 0.8289\n",
            "\n",
            "Epoch 00013: saving model to training_2/cp-0013.ckpt\n",
            "Epoch 14/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.3272 - accuracy: 0.8562 - val_loss: 0.3801 - val_accuracy: 0.8255\n",
            "\n",
            "Epoch 00014: saving model to training_2/cp-0014.ckpt\n",
            "Epoch 15/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.3109 - accuracy: 0.8658 - val_loss: 0.4254 - val_accuracy: 0.8200\n",
            "\n",
            "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
            "Epoch 16/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.2925 - accuracy: 0.8761 - val_loss: 0.4231 - val_accuracy: 0.8215\n",
            "\n",
            "Epoch 00016: saving model to training_2/cp-0016.ckpt\n",
            "Epoch 17/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.2687 - accuracy: 0.8873 - val_loss: 0.4088 - val_accuracy: 0.8289\n",
            "\n",
            "Epoch 00017: saving model to training_2/cp-0017.ckpt\n",
            "Epoch 18/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.2455 - accuracy: 0.9008 - val_loss: 0.4534 - val_accuracy: 0.8150\n",
            "\n",
            "Epoch 00018: saving model to training_2/cp-0018.ckpt\n",
            "Epoch 19/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.2231 - accuracy: 0.9130 - val_loss: 0.5043 - val_accuracy: 0.8046\n",
            "\n",
            "Epoch 00019: saving model to training_2/cp-0019.ckpt\n",
            "Epoch 20/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.2007 - accuracy: 0.9244 - val_loss: 0.5394 - val_accuracy: 0.8086\n",
            "\n",
            "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
            "Epoch 21/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.1822 - accuracy: 0.9328 - val_loss: 0.6097 - val_accuracy: 0.8046\n",
            "\n",
            "Epoch 00021: saving model to training_2/cp-0021.ckpt\n",
            "Epoch 22/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.1654 - accuracy: 0.9409 - val_loss: 0.6157 - val_accuracy: 0.8081\n",
            "\n",
            "Epoch 00022: saving model to training_2/cp-0022.ckpt\n",
            "Epoch 23/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.1550 - accuracy: 0.9446 - val_loss: 0.6035 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00023: saving model to training_2/cp-0023.ckpt\n",
            "Epoch 24/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.1384 - accuracy: 0.9515 - val_loss: 0.5720 - val_accuracy: 0.7996\n",
            "\n",
            "Epoch 00024: saving model to training_2/cp-0024.ckpt\n",
            "Epoch 25/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.1248 - accuracy: 0.9580 - val_loss: 0.7226 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
            "Epoch 26/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.1167 - accuracy: 0.9614 - val_loss: 0.7463 - val_accuracy: 0.7976\n",
            "\n",
            "Epoch 00026: saving model to training_2/cp-0026.ckpt\n",
            "Epoch 27/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.1129 - accuracy: 0.9626 - val_loss: 0.7209 - val_accuracy: 0.8056\n",
            "\n",
            "Epoch 00027: saving model to training_2/cp-0027.ckpt\n",
            "Epoch 28/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.1010 - accuracy: 0.9668 - val_loss: 0.7906 - val_accuracy: 0.7902\n",
            "\n",
            "Epoch 00028: saving model to training_2/cp-0028.ckpt\n",
            "Epoch 29/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0924 - accuracy: 0.9701 - val_loss: 0.7293 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00029: saving model to training_2/cp-0029.ckpt\n",
            "Epoch 30/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0863 - accuracy: 0.9729 - val_loss: 0.8630 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
            "Epoch 31/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0823 - accuracy: 0.9736 - val_loss: 0.7843 - val_accuracy: 0.7926\n",
            "\n",
            "Epoch 00031: saving model to training_2/cp-0031.ckpt\n",
            "Epoch 32/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0721 - accuracy: 0.9785 - val_loss: 0.9018 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00032: saving model to training_2/cp-0032.ckpt\n",
            "Epoch 33/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0754 - accuracy: 0.9770 - val_loss: 0.8358 - val_accuracy: 0.8001\n",
            "\n",
            "Epoch 00033: saving model to training_2/cp-0033.ckpt\n",
            "Epoch 34/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0698 - accuracy: 0.9797 - val_loss: 0.8805 - val_accuracy: 0.7966\n",
            "\n",
            "Epoch 00034: saving model to training_2/cp-0034.ckpt\n",
            "Epoch 35/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0717 - accuracy: 0.9790 - val_loss: 0.9320 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
            "Epoch 36/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0685 - accuracy: 0.9798 - val_loss: 0.8634 - val_accuracy: 0.7961\n",
            "\n",
            "Epoch 00036: saving model to training_2/cp-0036.ckpt\n",
            "Epoch 37/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0656 - accuracy: 0.9805 - val_loss: 0.8783 - val_accuracy: 0.7986\n",
            "\n",
            "Epoch 00037: saving model to training_2/cp-0037.ckpt\n",
            "Epoch 38/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0602 - accuracy: 0.9832 - val_loss: 0.7300 - val_accuracy: 0.7897\n",
            "\n",
            "Epoch 00038: saving model to training_2/cp-0038.ckpt\n",
            "Epoch 39/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0591 - accuracy: 0.9833 - val_loss: 0.8774 - val_accuracy: 0.7812\n",
            "\n",
            "Epoch 00039: saving model to training_2/cp-0039.ckpt\n",
            "Epoch 40/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0613 - accuracy: 0.9835 - val_loss: 0.8311 - val_accuracy: 0.7961\n",
            "\n",
            "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
            "Epoch 41/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0587 - accuracy: 0.9830 - val_loss: 0.8671 - val_accuracy: 0.7971\n",
            "\n",
            "Epoch 00041: saving model to training_2/cp-0041.ckpt\n",
            "Epoch 42/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0612 - accuracy: 0.9823 - val_loss: 0.9486 - val_accuracy: 0.7971\n",
            "\n",
            "Epoch 00042: saving model to training_2/cp-0042.ckpt\n",
            "Epoch 43/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0512 - accuracy: 0.9861 - val_loss: 0.9379 - val_accuracy: 0.7976\n",
            "\n",
            "Epoch 00043: saving model to training_2/cp-0043.ckpt\n",
            "Epoch 44/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0466 - accuracy: 0.9879 - val_loss: 0.9430 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00044: saving model to training_2/cp-0044.ckpt\n",
            "Epoch 45/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0526 - accuracy: 0.9857 - val_loss: 0.8581 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
            "Epoch 46/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0486 - accuracy: 0.9866 - val_loss: 0.8834 - val_accuracy: 0.7996\n",
            "\n",
            "Epoch 00046: saving model to training_2/cp-0046.ckpt\n",
            "Epoch 47/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0506 - accuracy: 0.9866 - val_loss: 0.8834 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00047: saving model to training_2/cp-0047.ckpt\n",
            "Epoch 48/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0459 - accuracy: 0.9876 - val_loss: 0.9707 - val_accuracy: 0.7911\n",
            "\n",
            "Epoch 00048: saving model to training_2/cp-0048.ckpt\n",
            "Epoch 49/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0503 - accuracy: 0.9861 - val_loss: 0.8108 - val_accuracy: 0.7852\n",
            "\n",
            "Epoch 00049: saving model to training_2/cp-0049.ckpt\n",
            "Epoch 50/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0468 - accuracy: 0.9873 - val_loss: 0.8867 - val_accuracy: 0.7936\n",
            "\n",
            "Epoch 00050: saving model to training_2/cp-0050.ckpt\n",
            "Epoch 51/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0460 - accuracy: 0.9875 - val_loss: 0.8732 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00051: saving model to training_2/cp-0051.ckpt\n",
            "Epoch 52/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0448 - accuracy: 0.9886 - val_loss: 0.8882 - val_accuracy: 0.8046\n",
            "\n",
            "Epoch 00052: saving model to training_2/cp-0052.ckpt\n",
            "Epoch 53/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0442 - accuracy: 0.9881 - val_loss: 0.9921 - val_accuracy: 0.7926\n",
            "\n",
            "Epoch 00053: saving model to training_2/cp-0053.ckpt\n",
            "Epoch 54/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0371 - accuracy: 0.9907 - val_loss: 0.9467 - val_accuracy: 0.7986\n",
            "\n",
            "Epoch 00054: saving model to training_2/cp-0054.ckpt\n",
            "Epoch 55/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0459 - accuracy: 0.9872 - val_loss: 0.9435 - val_accuracy: 0.7961\n",
            "\n",
            "Epoch 00055: saving model to training_2/cp-0055.ckpt\n",
            "Epoch 56/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0413 - accuracy: 0.9886 - val_loss: 1.0390 - val_accuracy: 0.7872\n",
            "\n",
            "Epoch 00056: saving model to training_2/cp-0056.ckpt\n",
            "Epoch 57/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0441 - accuracy: 0.9879 - val_loss: 0.9736 - val_accuracy: 0.7966\n",
            "\n",
            "Epoch 00057: saving model to training_2/cp-0057.ckpt\n",
            "Epoch 58/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0449 - accuracy: 0.9880 - val_loss: 1.0696 - val_accuracy: 0.7966\n",
            "\n",
            "Epoch 00058: saving model to training_2/cp-0058.ckpt\n",
            "Epoch 59/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0384 - accuracy: 0.9904 - val_loss: 0.9740 - val_accuracy: 0.8056\n",
            "\n",
            "Epoch 00059: saving model to training_2/cp-0059.ckpt\n",
            "Epoch 60/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0376 - accuracy: 0.9899 - val_loss: 0.9554 - val_accuracy: 0.7911\n",
            "\n",
            "Epoch 00060: saving model to training_2/cp-0060.ckpt\n",
            "Epoch 61/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0368 - accuracy: 0.9905 - val_loss: 1.1118 - val_accuracy: 0.8021\n",
            "\n",
            "Epoch 00061: saving model to training_2/cp-0061.ckpt\n",
            "Epoch 62/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0447 - accuracy: 0.9878 - val_loss: 0.8934 - val_accuracy: 0.8021\n",
            "\n",
            "Epoch 00062: saving model to training_2/cp-0062.ckpt\n",
            "Epoch 63/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0344 - accuracy: 0.9910 - val_loss: 1.0326 - val_accuracy: 0.7976\n",
            "\n",
            "Epoch 00063: saving model to training_2/cp-0063.ckpt\n",
            "Epoch 64/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0353 - accuracy: 0.9904 - val_loss: 0.9370 - val_accuracy: 0.7946\n",
            "\n",
            "Epoch 00064: saving model to training_2/cp-0064.ckpt\n",
            "Epoch 65/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 1.1146 - val_accuracy: 0.7907\n",
            "\n",
            "Epoch 00065: saving model to training_2/cp-0065.ckpt\n",
            "Epoch 66/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 0.9979 - val_accuracy: 0.8130\n",
            "\n",
            "Epoch 00066: saving model to training_2/cp-0066.ckpt\n",
            "Epoch 67/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 1.0366 - val_accuracy: 0.7966\n",
            "\n",
            "Epoch 00067: saving model to training_2/cp-0067.ckpt\n",
            "Epoch 68/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.9847 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00068: saving model to training_2/cp-0068.ckpt\n",
            "Epoch 69/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0345 - accuracy: 0.9903 - val_loss: 0.9876 - val_accuracy: 0.8076\n",
            "\n",
            "Epoch 00069: saving model to training_2/cp-0069.ckpt\n",
            "Epoch 70/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0341 - accuracy: 0.9907 - val_loss: 1.0852 - val_accuracy: 0.8001\n",
            "\n",
            "Epoch 00070: saving model to training_2/cp-0070.ckpt\n",
            "Epoch 71/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0332 - accuracy: 0.9909 - val_loss: 1.0051 - val_accuracy: 0.8011\n",
            "\n",
            "Epoch 00071: saving model to training_2/cp-0071.ckpt\n",
            "Epoch 72/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 1.0641 - val_accuracy: 0.8016\n",
            "\n",
            "Epoch 00072: saving model to training_2/cp-0072.ckpt\n",
            "Epoch 73/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0340 - accuracy: 0.9906 - val_loss: 1.1352 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00073: saving model to training_2/cp-0073.ckpt\n",
            "Epoch 74/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0383 - accuracy: 0.9892 - val_loss: 1.0516 - val_accuracy: 0.7842\n",
            "\n",
            "Epoch 00074: saving model to training_2/cp-0074.ckpt\n",
            "Epoch 75/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 1.1595 - val_accuracy: 0.7911\n",
            "\n",
            "Epoch 00075: saving model to training_2/cp-0075.ckpt\n",
            "Epoch 76/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 1.0721 - val_accuracy: 0.8026\n",
            "\n",
            "Epoch 00076: saving model to training_2/cp-0076.ckpt\n",
            "Epoch 77/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 1.2077 - val_accuracy: 0.7996\n",
            "\n",
            "Epoch 00077: saving model to training_2/cp-0077.ckpt\n",
            "Epoch 78/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.9876 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00078: saving model to training_2/cp-0078.ckpt\n",
            "Epoch 79/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 1.2594 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00079: saving model to training_2/cp-0079.ckpt\n",
            "Epoch 80/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 1.1773 - val_accuracy: 0.8021\n",
            "\n",
            "Epoch 00080: saving model to training_2/cp-0080.ckpt\n",
            "Epoch 81/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 1.2024 - val_accuracy: 0.8071\n",
            "\n",
            "Epoch 00081: saving model to training_2/cp-0081.ckpt\n",
            "Epoch 82/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 1.0357 - val_accuracy: 0.8016\n",
            "\n",
            "Epoch 00082: saving model to training_2/cp-0082.ckpt\n",
            "Epoch 83/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 1.1472 - val_accuracy: 0.8011\n",
            "\n",
            "Epoch 00083: saving model to training_2/cp-0083.ckpt\n",
            "Epoch 84/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 1.2022 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00084: saving model to training_2/cp-0084.ckpt\n",
            "Epoch 85/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0209 - accuracy: 0.9922 - val_loss: 1.0559 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00085: saving model to training_2/cp-0085.ckpt\n",
            "Epoch 86/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 1.2370 - val_accuracy: 0.8021\n",
            "\n",
            "Epoch 00086: saving model to training_2/cp-0086.ckpt\n",
            "Epoch 87/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 1.1291 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00087: saving model to training_2/cp-0087.ckpt\n",
            "Epoch 88/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 1.1834 - val_accuracy: 0.8011\n",
            "\n",
            "Epoch 00088: saving model to training_2/cp-0088.ckpt\n",
            "Epoch 89/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 1.2606 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00089: saving model to training_2/cp-0089.ckpt\n",
            "Epoch 90/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 1.2144 - val_accuracy: 0.8046\n",
            "\n",
            "Epoch 00090: saving model to training_2/cp-0090.ckpt\n",
            "Epoch 91/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 1.2283 - val_accuracy: 0.8001\n",
            "\n",
            "Epoch 00091: saving model to training_2/cp-0091.ckpt\n",
            "Epoch 92/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 1.1835 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00092: saving model to training_2/cp-0092.ckpt\n",
            "Epoch 93/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 1.1275 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00093: saving model to training_2/cp-0093.ckpt\n",
            "Epoch 94/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 1.1324 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00094: saving model to training_2/cp-0094.ckpt\n",
            "Epoch 95/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.2206 - val_accuracy: 0.7996\n",
            "\n",
            "Epoch 00095: saving model to training_2/cp-0095.ckpt\n",
            "Epoch 96/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 1.2107 - val_accuracy: 0.8081\n",
            "\n",
            "Epoch 00096: saving model to training_2/cp-0096.ckpt\n",
            "Epoch 97/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 1.1774 - val_accuracy: 0.8021\n",
            "\n",
            "Epoch 00097: saving model to training_2/cp-0097.ckpt\n",
            "Epoch 98/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 1.1105 - val_accuracy: 0.8095\n",
            "\n",
            "Epoch 00098: saving model to training_2/cp-0098.ckpt\n",
            "Epoch 99/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 1.3181 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00099: saving model to training_2/cp-0099.ckpt\n",
            "Epoch 100/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 1.1723 - val_accuracy: 0.8001\n",
            "\n",
            "Epoch 00100: saving model to training_2/cp-0100.ckpt\n",
            "Epoch 101/30000\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 1.3712 - val_accuracy: 0.7996\n",
            "\n",
            "Epoch 00101: saving model to training_2/cp-0101.ckpt\n",
            "Epoch 102/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 1.3207 - val_accuracy: 0.8071\n",
            "\n",
            "Epoch 00102: saving model to training_2/cp-0102.ckpt\n",
            "Epoch 103/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.4272 - val_accuracy: 0.7926\n",
            "\n",
            "Epoch 00103: saving model to training_2/cp-0103.ckpt\n",
            "Epoch 104/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.2923 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00104: saving model to training_2/cp-0104.ckpt\n",
            "Epoch 105/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 1.5621 - val_accuracy: 0.8031\n",
            "\n",
            "Epoch 00105: saving model to training_2/cp-0105.ckpt\n",
            "Epoch 106/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 1.2439 - val_accuracy: 0.7911\n",
            "\n",
            "Epoch 00106: saving model to training_2/cp-0106.ckpt\n",
            "Epoch 107/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.4741 - val_accuracy: 0.8001\n",
            "\n",
            "Epoch 00107: saving model to training_2/cp-0107.ckpt\n",
            "Epoch 108/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 1.3247 - val_accuracy: 0.8051\n",
            "\n",
            "Epoch 00108: saving model to training_2/cp-0108.ckpt\n",
            "Epoch 109/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 1.2958 - val_accuracy: 0.7961\n",
            "\n",
            "Epoch 00109: saving model to training_2/cp-0109.ckpt\n",
            "Epoch 110/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 1.2905 - val_accuracy: 0.7907\n",
            "\n",
            "Epoch 00110: saving model to training_2/cp-0110.ckpt\n",
            "Epoch 111/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 1.2848 - val_accuracy: 0.8031\n",
            "\n",
            "Epoch 00111: saving model to training_2/cp-0111.ckpt\n",
            "Epoch 112/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 1.2629 - val_accuracy: 0.8031\n",
            "\n",
            "Epoch 00112: saving model to training_2/cp-0112.ckpt\n",
            "Epoch 113/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 1.3369 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00113: saving model to training_2/cp-0113.ckpt\n",
            "Epoch 114/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0316 - accuracy: 0.9897 - val_loss: 1.0970 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00114: saving model to training_2/cp-0114.ckpt\n",
            "Epoch 115/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 1.1773 - val_accuracy: 0.8001\n",
            "\n",
            "Epoch 00115: saving model to training_2/cp-0115.ckpt\n",
            "Epoch 116/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 1.3323 - val_accuracy: 0.8001\n",
            "\n",
            "Epoch 00116: saving model to training_2/cp-0116.ckpt\n",
            "Epoch 117/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 1.3910 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00117: saving model to training_2/cp-0117.ckpt\n",
            "Epoch 118/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 1.3236 - val_accuracy: 0.8051\n",
            "\n",
            "Epoch 00118: saving model to training_2/cp-0118.ckpt\n",
            "Epoch 119/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 1.5139 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00119: saving model to training_2/cp-0119.ckpt\n",
            "Epoch 120/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.2573 - val_accuracy: 0.8016\n",
            "\n",
            "Epoch 00120: saving model to training_2/cp-0120.ckpt\n",
            "Epoch 121/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 1.4817 - val_accuracy: 0.8071\n",
            "\n",
            "Epoch 00121: saving model to training_2/cp-0121.ckpt\n",
            "Epoch 122/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 1.4279 - val_accuracy: 0.8091\n",
            "\n",
            "Epoch 00122: saving model to training_2/cp-0122.ckpt\n",
            "Epoch 123/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 1.4183 - val_accuracy: 0.7946\n",
            "\n",
            "Epoch 00123: saving model to training_2/cp-0123.ckpt\n",
            "Epoch 124/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 1.3742 - val_accuracy: 0.8066\n",
            "\n",
            "Epoch 00124: saving model to training_2/cp-0124.ckpt\n",
            "Epoch 125/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 1.5113 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00125: saving model to training_2/cp-0125.ckpt\n",
            "Epoch 126/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 1.4523 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00126: saving model to training_2/cp-0126.ckpt\n",
            "Epoch 127/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 1.3165 - val_accuracy: 0.8051\n",
            "\n",
            "Epoch 00127: saving model to training_2/cp-0127.ckpt\n",
            "Epoch 128/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 1.3261 - val_accuracy: 0.8071\n",
            "\n",
            "Epoch 00128: saving model to training_2/cp-0128.ckpt\n",
            "Epoch 129/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0085 - accuracy: 0.9967 - val_loss: 1.4610 - val_accuracy: 0.8001\n",
            "\n",
            "Epoch 00129: saving model to training_2/cp-0129.ckpt\n",
            "Epoch 130/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 1.2457 - val_accuracy: 0.7921\n",
            "\n",
            "Epoch 00130: saving model to training_2/cp-0130.ckpt\n",
            "Epoch 131/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: 1.4268 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00131: saving model to training_2/cp-0131.ckpt\n",
            "Epoch 132/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 1.3989 - val_accuracy: 0.7936\n",
            "\n",
            "Epoch 00132: saving model to training_2/cp-0132.ckpt\n",
            "Epoch 133/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 1.4868 - val_accuracy: 0.7961\n",
            "\n",
            "Epoch 00133: saving model to training_2/cp-0133.ckpt\n",
            "Epoch 134/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 1.4409 - val_accuracy: 0.8031\n",
            "\n",
            "Epoch 00134: saving model to training_2/cp-0134.ckpt\n",
            "Epoch 135/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 1.3134 - val_accuracy: 0.8056\n",
            "\n",
            "Epoch 00135: saving model to training_2/cp-0135.ckpt\n",
            "Epoch 136/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.9324 - val_accuracy: 0.7976\n",
            "\n",
            "Epoch 00136: saving model to training_2/cp-0136.ckpt\n",
            "Epoch 137/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 1.3153 - val_accuracy: 0.7951\n",
            "\n",
            "Epoch 00137: saving model to training_2/cp-0137.ckpt\n",
            "Epoch 138/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 1.0786 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00138: saving model to training_2/cp-0138.ckpt\n",
            "Epoch 139/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 1.1939 - val_accuracy: 0.8066\n",
            "\n",
            "Epoch 00139: saving model to training_2/cp-0139.ckpt\n",
            "Epoch 140/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 1.2954 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00140: saving model to training_2/cp-0140.ckpt\n",
            "Epoch 141/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0058 - accuracy: 0.9977 - val_loss: 1.3447 - val_accuracy: 0.7971\n",
            "\n",
            "Epoch 00141: saving model to training_2/cp-0141.ckpt\n",
            "Epoch 142/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 1.5318 - val_accuracy: 0.8041\n",
            "\n",
            "Epoch 00142: saving model to training_2/cp-0142.ckpt\n",
            "Epoch 143/30000\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 1.5545 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00143: saving model to training_2/cp-0143.ckpt\n",
            "Epoch 144/30000\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 1.5364 - val_accuracy: 0.8051\n",
            "\n",
            "Epoch 00144: saving model to training_2/cp-0144.ckpt\n",
            "Epoch 145/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 1.5631 - val_accuracy: 0.8046\n",
            "\n",
            "Epoch 00145: saving model to training_2/cp-0145.ckpt\n",
            "Epoch 146/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 1.6674 - val_accuracy: 0.7986\n",
            "\n",
            "Epoch 00146: saving model to training_2/cp-0146.ckpt\n",
            "Epoch 147/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 1.4581 - val_accuracy: 0.8006\n",
            "\n",
            "Epoch 00147: saving model to training_2/cp-0147.ckpt\n",
            "Epoch 148/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.5851 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00148: saving model to training_2/cp-0148.ckpt\n",
            "Epoch 149/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 1.5105 - val_accuracy: 0.7966\n",
            "\n",
            "Epoch 00149: saving model to training_2/cp-0149.ckpt\n",
            "Epoch 150/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0095 - accuracy: 0.9961 - val_loss: 1.4184 - val_accuracy: 0.7981\n",
            "\n",
            "Epoch 00150: saving model to training_2/cp-0150.ckpt\n",
            "Epoch 151/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 1.4044 - val_accuracy: 0.7941\n",
            "\n",
            "Epoch 00151: saving model to training_2/cp-0151.ckpt\n",
            "Epoch 152/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0107 - accuracy: 0.9959 - val_loss: 1.3000 - val_accuracy: 0.7882\n",
            "\n",
            "Epoch 00152: saving model to training_2/cp-0152.ckpt\n",
            "Epoch 153/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 1.5508 - val_accuracy: 0.7976\n",
            "\n",
            "Epoch 00153: saving model to training_2/cp-0153.ckpt\n",
            "Epoch 154/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 1.6080 - val_accuracy: 0.7902\n",
            "\n",
            "Epoch 00154: saving model to training_2/cp-0154.ckpt\n",
            "Epoch 155/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.4134 - val_accuracy: 0.8021\n",
            "\n",
            "Epoch 00155: saving model to training_2/cp-0155.ckpt\n",
            "Epoch 156/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.1652 - val_accuracy: 0.7976\n",
            "\n",
            "Epoch 00156: saving model to training_2/cp-0156.ckpt\n",
            "Epoch 157/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 1.2929 - val_accuracy: 0.7991\n",
            "\n",
            "Epoch 00157: saving model to training_2/cp-0157.ckpt\n",
            "Epoch 158/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 1.4631 - val_accuracy: 0.7936\n",
            "\n",
            "Epoch 00158: saving model to training_2/cp-0158.ckpt\n",
            "Epoch 159/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 1.5540 - val_accuracy: 0.8021\n",
            "\n",
            "Epoch 00159: saving model to training_2/cp-0159.ckpt\n",
            "Epoch 160/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 1.3703 - val_accuracy: 0.7986\n",
            "\n",
            "Epoch 00160: saving model to training_2/cp-0160.ckpt\n",
            "Epoch 161/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.4505 - val_accuracy: 0.8051\n",
            "\n",
            "Epoch 00161: saving model to training_2/cp-0161.ckpt\n",
            "Epoch 162/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.3259 - val_accuracy: 0.7996\n",
            "\n",
            "Epoch 00162: saving model to training_2/cp-0162.ckpt\n",
            "Epoch 163/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 1.3762 - val_accuracy: 0.7951\n",
            "\n",
            "Epoch 00163: saving model to training_2/cp-0163.ckpt\n",
            "Epoch 164/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 1.5027 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00164: saving model to training_2/cp-0164.ckpt\n",
            "Epoch 165/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 1.5533 - val_accuracy: 0.7956\n",
            "\n",
            "Epoch 00165: saving model to training_2/cp-0165.ckpt\n",
            "Epoch 166/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 1.2896 - val_accuracy: 0.8066\n",
            "\n",
            "Epoch 00166: saving model to training_2/cp-0166.ckpt\n",
            "Epoch 167/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 1.4683 - val_accuracy: 0.8091\n",
            "\n",
            "Epoch 00167: saving model to training_2/cp-0167.ckpt\n",
            "Epoch 168/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 1.6395 - val_accuracy: 0.8031\n",
            "\n",
            "Epoch 00168: saving model to training_2/cp-0168.ckpt\n",
            "Epoch 169/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.9047 - val_accuracy: 0.7986\n",
            "\n",
            "Epoch 00169: saving model to training_2/cp-0169.ckpt\n",
            "Epoch 170/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0546 - accuracy: 0.9825 - val_loss: 0.9560 - val_accuracy: 0.7996\n",
            "\n",
            "Epoch 00170: saving model to training_2/cp-0170.ckpt\n",
            "Epoch 171/30000\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 0.0365 - accuracy: 0.9885 - val_loss: 1.0064 - val_accuracy: 0.8051\n",
            "\n",
            "Epoch 00171: saving model to training_2/cp-0171.ckpt\n",
            "Epoch 172/30000\n",
            " 67/438 [===>..........................] - ETA: 13s - loss: 0.0371 - accuracy: 0.9876"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ac59605fb6b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \"\"\"\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}