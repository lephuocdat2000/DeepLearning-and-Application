{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled160.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiIQUn4SXjsw0zyJyHfKqx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/DeepLearning-and-Application/blob/main/CNN%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WYVGf-52FS_",
        "outputId": "f09929ca-96f6-43a7-8f70-e496fcc715d9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Y8yQCP2v4i"
      },
      "source": [
        "import scipy.io.wavfile\n",
        "import numpy as np\n",
        "import sys\n",
        "import glob \n",
        "import librosa\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "from IPython.display import Audio\n",
        "### Time Distributed ConvNet imports ###\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import Image\n",
        "from glob import glob\n",
        "import pickle\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "### Audioimport ###\n",
        "import IPython\n",
        "\n",
        "### Warning ###\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S_rhPQp23B6"
      },
      "source": [
        "#Extract signals and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwrOqCG-2zDE"
      },
      "source": [
        "#Extract filename and label\n",
        "data_path = '/content/drive/MyDrive/Nhận dạng/Data Voice'\n",
        "emotions=os.listdir(data_path)\n",
        "filenames = []\n",
        "labels = []\n",
        "for emotion in emotions:\n",
        "   file_names = os.listdir(os.path.join(data_path,emotion))\n",
        "   for name in file_names:\n",
        "     if name!='transcript': \n",
        "         filenames.append(name.split(\".\")[0])\n",
        "         labels.append(np.float(name[0]))\n",
        "\n",
        "filenames = np.array(filenames)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEIj0Wc93cwW"
      },
      "source": [
        "#Build audio vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsUJTgDr3Zv2",
        "outputId": "fdce36ad-3219-4640-d6d7-f7dd0a2ce5e6"
      },
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTmaq0K1HPfg"
      },
      "source": [
        "#Extract signal\n",
        "sample_rate = 16000     \n",
        "max_pad_len = 49100\n",
        "signals = []\n",
        "\n",
        "for idx,name in enumerate(filenames):\n",
        "    emotion_path = os.path.join(data_path,emotions[int(labels[idx])])\n",
        "    file_path = os.path.join(emotion_path,name+'.wav')\n",
        "    y,sr = librosa.load(file_path, sr=sample_rate)\n",
        "    y = zscore(y)\n",
        "    if len(y) < max_pad_len:    \n",
        "        y_padded = np.zeros(max_pad_len)\n",
        "        y_padded[:len(y)] = y\n",
        "        y = y_padded\n",
        "    elif len(y) > max_pad_len:\n",
        "        y = np.asarray(y[:max_pad_len])\n",
        "    signals.append(y)\n",
        "\n",
        "signals = np.array(signals)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xORVl7xaDT3f"
      },
      "source": [
        "#Show Audio\n",
        "\n",
        "random_idx = np.random.randint(len(labels))\n",
        "random_idx=1\n",
        "random_label = labels[random_idx]\n",
        "random_signal = signals[random_idx]\n",
        "random_filename = filenames[random_idx]\n",
        "\n",
        "# Plot signal wave\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(np.arange(len(random_signal))/float(sample_rate), random_signal)\n",
        "plt.xlim((np.arange(len(random_signal))/float(sample_rate))[0], (np.arange(len(random_signal))/float(sample_rate))[-1])\n",
        "plt.xlabel('Time (s)', fontsize=16)\n",
        "plt.ylabel('Amplitude (dB)', fontsize=16)\n",
        "plt.title(\"Signal wave of file '{}' with label {}\".format(random_filename, random_label), fontsize=18)\n",
        "plt.show()\n",
        "\n",
        "# Play audio file\n",
        "print(\"Audio file '{}':\".format(random_filename))\n",
        "Audio(random_signal, rate=sample_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvGDFQcH-29V"
      },
      "source": [
        "#Augment Noisy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oiy_694E-zbz"
      },
      "source": [
        "nb_augmented = 2\n",
        "\n",
        "# Function to add noise to a signals with a desired Signal Noise ratio (SNR)\n",
        "def noisy_signal(signal, snr_low=15, snr_high=30, nb_augmented=2):\n",
        "    \n",
        "    # Signal length\n",
        "    signal_len = len(signal)\n",
        "\n",
        "    # Generate White noise\n",
        "    noise = np.random.normal(size=(nb_augmented, signal_len))\n",
        "    \n",
        "    # Compute signal and noise power\n",
        "    s_power = np.sum((signal / (2.0 ** 15)) ** 2) / signal_len\n",
        "    n_power = np.sum((noise / (2.0 ** 15)) ** 2, axis=1) / signal_len\n",
        "    \n",
        "    # Random SNR: Uniform [15, 30]\n",
        "    snr = np.random.randint(snr_low, snr_high)\n",
        "    \n",
        "    # Compute K coeff for each noise\n",
        "    K = np.sqrt((s_power / n_power) * 10 ** (- snr / 10))\n",
        "    K = np.ones((signal_len, nb_augmented)) * K\n",
        "    \n",
        "    # Generate noisy signal\n",
        "    return signal + K.T * noise"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urmAfxm3_mHm",
        "outputId": "3550aa3f-cc8e-4aa7-b217-25f7edfffc9f"
      },
      "source": [
        "print(\"Data Augmentation: START\")\n",
        "augmented_signals = list(map(noisy_signal, signals))\n",
        "print(\"Data Augmentation: END!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Augmentation: START\n",
            "Data Augmentation: END!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXZrSdujDScA"
      },
      "source": [
        "#Show raw and noisy audio\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(len(random_signal))/float(sample_rate), random_signal)\n",
        "plt.xlim((np.arange(len(random_signal))/float(sample_rate))[0], (np.arange(len(random_signal))/float(sample_rate))[-1])\n",
        "plt.xlabel('Time (s)', fontsize=16)\n",
        "plt.ylabel('Amplitude (dB)', fontsize=16)\n",
        "plt.title(\"Signal wave of file '{}' \".format(random_filename), fontsize=18)\n",
        "\n",
        "# Plot signal wave with noise\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(np.arange(len(random_signal))/float(sample_rate), augmented_signals[random_idx][0])\n",
        "plt.xlim((np.arange(len(random_signal))/float(sample_rate))[0], (np.arange(len(random_signal))/float(sample_rate))[-1])\n",
        "plt.xlabel('Time (s)', fontsize=16)\n",
        "plt.ylabel('Amplitude (dB)', fontsize=16)\n",
        "plt.title(\"Signal wave of file '{}' with Noise\".format(random_filename), fontsize=18)\n",
        "plt.show()\n",
        "\n",
        "# Play audio file\n",
        "print(\"Audio file '{}':\".format(random_filename))\n",
        "IPython.display.display(Audio(random_signal, rate=sample_rate))\n",
        "\n",
        "# Play same audio file with noise\n",
        "print(\"Audio file '{}' with noise:\".format(random_filename))\n",
        "IPython.display.display(Audio(augmented_signals[random_idx][0], rate=sample_rate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0Xltq3eqkAu"
      },
      "source": [
        "###Extract mel_spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYwqnQSdEsSP"
      },
      "source": [
        "def mel_spectrogram(y, sr=16000, n_fft=512, win_length=256, hop_length=128, window='hamming', n_mels=128, fmax=4000):\n",
        "    \n",
        "    # Compute spectogram\n",
        "    mel_spect = np.abs(librosa.stft(y, n_fft=n_fft, window=window, win_length=win_length, hop_length=hop_length)) ** 2\n",
        "    \n",
        "    # Compute mel spectrogram\n",
        "    mel_spect = librosa.feature.melspectrogram(S=mel_spect, sr=sr, n_mels=n_mels, fmax=fmax)\n",
        "    \n",
        "    # Compute log-mel spectrogram\n",
        "    mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
        "    \n",
        "    return mel_spect"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNb1SiBkEvFX",
        "outputId": "02cfa62e-553a-4ad8-bc45-42630bcd1b6b"
      },
      "source": [
        "# Start feature extraction\n",
        "print(\"Feature extraction: START\")\n",
        "\n",
        "# Compute spectogram for all audio file\n",
        "mel_spects = np.asarray(list(map(mel_spectrogram, signals)))\n",
        "augmented_mel_spects = [np.asarray(list(map(mel_spectrogram, augmented_signals[i]))) for i in range(len(augmented_signals))]\n",
        "\n",
        "# Stop feature extraction\n",
        "print(\"Feature extraction: END!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature extraction: START\n",
            "Feature extraction: END!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7qCoBxyDRBP"
      },
      "source": [
        "# Plot one random Spectogram \n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.imshow(mel_spects[np.random.randint(len(mel_spects))], origin='lower', aspect='auto', cmap='viridis')\n",
        "plt.title('Log-Mel Spectrogram of an audio file', fontsize=26)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW5uQeEFqtLK"
      },
      "source": [
        "Split train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwWLK2aAIQBG"
      },
      "source": [
        "MEL_SPECT_train, MEL_SPECT_test, AUG_MEL_SPECT_train, AUG_MEL_SPECT_test, label_train, label_test = train_test_split(mel_spects, augmented_mel_spects, labels, test_size=0.2,random_state=42)\n",
        "\n",
        "# Build augmented labels and train\n",
        "aug_label_train = np.asarray(list(itertools.chain.from_iterable([[label] * nb_augmented for label in label_train])))\n",
        "AUG_MEL_SPECT_train = np.asarray(list(itertools.chain.from_iterable(AUG_MEL_SPECT_train)))\n",
        "\n",
        "# Concatenate original and augmented\n",
        "X_train = np.concatenate((MEL_SPECT_train, AUG_MEL_SPECT_train))\n",
        "y_train = np.concatenate((label_train, aug_label_train))\n",
        "\n",
        "# Build test set\n",
        "X_test = MEL_SPECT_test\n",
        "y_test = label_test\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK3pKp9sABXh"
      },
      "source": [
        "from numpy import save\n",
        "#train and test set of Vie-Vie model\n",
        "save('vie_X_train.npy',X_train)\n",
        "save('vie_X_test.npy',X_test)\n",
        "save('vie_y_train.npy',y_train)\n",
        "save('vie_y_test.npy',y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-fa9qZgq3Fx"
      },
      "source": [
        "Split to frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FleNQyWLJdc3"
      },
      "source": [
        "# Time distributed parameters\n",
        "win_ts = 128\n",
        "hop_ts = 64\n",
        "\n",
        "# Split spectrogram into frames\n",
        "def frame(x, win_step=128, win_size=64):\n",
        "    nb_frames = 1 + int((x.shape[2] - win_size) / win_step)\n",
        "    frames = np.zeros((x.shape[0], nb_frames, x.shape[1], win_size)).astype(np.float32)\n",
        "    for t in range(nb_frames):\n",
        "        frames[:,t,:,:] = np.copy(x[:,:,(t * win_step):(t * win_step + win_size)]).astype(np.float32)\n",
        "    return frames\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KujqxmjBofw"
      },
      "source": [
        "# Frame for TimeDistributed model\n",
        "X_train = frame(X_train, hop_ts, win_ts)\n",
        "X_test = frame(X_test, hop_ts, win_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY_eBBUeKHZ1",
        "outputId": "146137d1-4588-4cae-808b-11612b84f0dc"
      },
      "source": [
        "cd /content/drive/MyDrive/Nhận dạng\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Nhận dạng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qooqtU7-KPVa"
      },
      "source": [
        "#save x_train,y_train,x_test,y_test\n",
        "\n",
        "save('X_train.npy',X_train)\n",
        "save('X_test.npy',X_test)\n",
        "save('y_train.npy',y_train)\n",
        "save('y_test.npy',y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v06Zy8GBW8p"
      },
      "source": [
        "from numpy import load,save\n",
        "X_train = load('X_train.npy',allow_pickle=True)\n",
        "X_test = load('X_test.npy',allow_pickle=True)\n",
        "y_train = load('y_train.npy',allow_pickle = True)\n",
        "y_test = load('y_test.npy',allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6QhBVzMKzkO"
      },
      "source": [
        "#Encode label\n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(np.ravel(y_train)))\n",
        "y_test = np_utils.to_categorical(lb.transform(np.ravel(y_test)))\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] , X_train.shape[2], X_train.shape[3], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] , X_test.shape[2], X_test.shape[3], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UAcmRbmrJYi"
      },
      "source": [
        "Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LSeZSsltV1M"
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "# Define two sets of inputs: MFCC and FBANK\n",
        "input_y = Input(shape=X_train.shape[1:], name='Input_MELSPECT')\n",
        "\n",
        "## First LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_1_MELSPECT')(input_y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_1_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'), name='MaxPool_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_1_MELSPECT')(y)     \n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_2_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_2_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_2_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_3_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_3_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_3_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_4_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_4_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_4_MELSPECT')(y)  \n",
        "\n",
        "## Flat\n",
        "y = TimeDistributed(Flatten(), name='Flat_MELSPECT')(y)                      \n",
        "                               \n",
        "# Apply 2 LSTM layer and one FC\n",
        "y = LSTM(256, return_sequences=False, dropout=0.2, name='LSTM_1')(y)\n",
        "y = Dense(y_train.shape[1], activation='softmax', name='FC')(y)\n",
        "\n",
        "# Build final model\n",
        "model = Model(inputs=input_y, outputs=y)\n",
        "\n",
        "# Plot model graph\n",
        "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "Image(retina=True, filename='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqp272uMrLBs"
      },
      "source": [
        "Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuy3PiERDN75"
      },
      "source": [
        "# Compile model\n",
        "model.compile(optimizer=SGD(lr=0.001, decay=1e-6, momentum=0.8), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Save best model\n",
        "best_model_save = ModelCheckpoint('/content/drive/MyDrive/Model/[CNN-LSTM]Model.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, verbose=1, mode='max')\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(X_train, y_train, batch_size=64, epochs=200, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyxihZh1tUAa"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoLVc4gptREb"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQPibdMwoigR"
      },
      "source": [
        "#Train model Anh-Việt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a9BwoBxovOD"
      },
      "source": [
        "###Dowload dataset from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkSHdCZYsC-Y",
        "outputId": "13b35438-b5a8-4331-d9ef-3222e888e79d"
      },
      "source": [
        "!pip install opendatasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/3f/cdd30cbd950efdb1fa5c766ffb2c38d1da5314292b6cd226e3871171a776/opendatasets-0.1.20-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.41.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.5.30)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (5.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCnyTvQcvtuj"
      },
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUQLslRuv0uq"
      },
      "source": [
        "###Extract signals and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msUoEOH6wCr_"
      },
      "source": [
        "sample_rate = 16000     \n",
        "max_pad_len = 49100\n",
        "eng_signals = []\n",
        "eng_labels = []\n",
        "dataset_path = '/content/drive/MyDrive/Nhận dạng/ravdess-emotional-speech-audio'\n",
        "actors = os.listdir(dataset_path)\n",
        "\n",
        "for actor_file in actors:\n",
        "    actor_path = os.path.join(dataset_path,actor_file)\n",
        "    filenames = os.listdir(actor_path)\n",
        "    for name in filenames:\n",
        "        temp = int(name[6:8])\n",
        "        if (temp==1) or (temp==3) or (temp==4) or (temp==5):\n",
        "            if temp==1:  eng_labels.append(3)\n",
        "            elif temp==3: eng_labels.append(1)\n",
        "            elif temp==4: eng_labels.append(2)\n",
        "            else: eng_labels.append(0)\n",
        "            file_path = os.path.join(actor_path,name)\n",
        "            y,sr = librosa.load(file_path, sr=sample_rate)\n",
        "            y = zscore(y)\n",
        "            if len(y) < max_pad_len:    \n",
        "                y_padded = np.zeros(max_pad_len)\n",
        "                y_padded[:len(y)] = y\n",
        "                y = y_padded\n",
        "            elif len(y) > max_pad_len:\n",
        "                y = np.asarray(y[:max_pad_len])\n",
        "            eng_signals.append(y)\n",
        "\n",
        "eng_labels = np.array(eng_labels)\n",
        "eng_signals = np.array(eng_signals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxYoQ8YH4mYl"
      },
      "source": [
        "###Agumented Noisy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOzA6NU63fM-",
        "outputId": "3ce40307-cd7a-431f-cb78-078ca6335ea9"
      },
      "source": [
        "print(\"Data Augmentation: START\")\n",
        "eng_augmented_signals = list(map(noisy_signal, eng_signals))\n",
        "print(\"Data Augmentation: END!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Augmentation: START\n",
            "Data Augmentation: END!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lI9MsFx4y2g"
      },
      "source": [
        "###Extract Mel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrmNmT7f4yZS",
        "outputId": "16656c25-922c-4ab5-9e11-893ace8eccc2"
      },
      "source": [
        "# Start feature extraction\n",
        "print(\"Feature extraction: START\")\n",
        "\n",
        "# Compute spectogram for all audio file\n",
        "eng_mel_spects = np.asarray(list(map(mel_spectrogram, eng_signals)))\n",
        "eng_augmented_mel_spects = [np.asarray(list(map(mel_spectrogram, eng_augmented_signals[i]))) for i in range(len(eng_augmented_signals))]\n",
        "\n",
        "# Stop feature extraction\n",
        "print(\"Feature extraction: END!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature extraction: START\n",
            "Feature extraction: END!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-xHwo0F5wax"
      },
      "source": [
        "###Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTt0rdU_5vGH"
      },
      "source": [
        "# Build augmented labels and train\n",
        "eng_aug_labels = np.asarray(list(itertools.chain.from_iterable([[label] * nb_augmented for label in eng_labels])))\n",
        "eng_AUG_MEL_SPECTs = np.asarray(list(itertools.chain.from_iterable(eng_augmented_mel_spects)))\n",
        "eng_X_train = np.concatenate((eng_mel_spects,eng_AUG_MEL_SPECTs))\n",
        "eng_y_train = np.concatenate((eng_labels,eng_aug_labels))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsiPlEc7HI89",
        "outputId": "9a9311c7-e676-4622-a1e7-5f96673cc9a2"
      },
      "source": [
        "cd /content/drive/MyDrive/Nhận dạng"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Nhận dạng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQTIBl9T81zd"
      },
      "source": [
        "#Load test set - Vietnamese\n",
        "from numpy import load\n",
        "X_train = load('vie_X_train.npy',allow_pickle=True)\n",
        "X_test = load('vie_X_test.npy',allow_pickle=True)\n",
        "y_train = load('vie_y_train.npy',allow_pickle = True)\n",
        "y_test = load('vie_y_test.npy',allow_pickle=True)\n",
        "vie_X_test = np.concatenate((X_train,X_test))\n",
        "vie_y_test = np.concatenate((y_train,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i0Tod1jBlWg"
      },
      "source": [
        "# Frame for TimeDistributed model\n",
        "eng_X_train = frame(eng_X_train, hop_ts, win_ts)\n",
        "vie_X_test = frame(vie_X_test, hop_ts, win_ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmF50lsiBZxC"
      },
      "source": [
        "#Encode label\n",
        "\n",
        "lb = LabelEncoder()\n",
        "eng_y_train = np_utils.to_categorical(lb.fit_transform(np.ravel(eng_y_train)))\n",
        "vie_y_test = np_utils.to_categorical(lb.transform(np.ravel(vie_y_test)))\n",
        "\n",
        "eng_X_train = eng_X_train.reshape(eng_X_train.shape[0], eng_X_train.shape[1] , eng_X_train.shape[2], eng_X_train.shape[3], 1)\n",
        "vie_X_test = vie_X_test.reshape(vie_X_test.shape[0], vie_X_test.shape[1] , vie_X_test.shape[2], vie_X_test.shape[3], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLd-3V5tHUgy"
      },
      "source": [
        "from numpy import save\n",
        "\n",
        "save('eng-vie_X_train.npy',eng_X_train)\n",
        "save('eng-vie_X_test.npy',vie_X_test)\n",
        "save('eng_vie_y_train.npy',eng_y_train)\n",
        "save('eng_vie_y_test.npy',vie_y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrz5t5vgIjUp"
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "# Define two sets of inputs: MFCC and FBANK\n",
        "input_y = Input(shape=eng_X_train.shape[1:], name='Input_MELSPECT')\n",
        "\n",
        "## First LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_1_MELSPECT')(input_y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_1_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'), name='MaxPool_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_1_MELSPECT')(y)     \n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_2_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_2_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_2_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_3_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_3_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_3_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_4_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_4_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_4_MELSPECT')(y)  \n",
        "\n",
        "## Flat\n",
        "y = TimeDistributed(Flatten(), name='Flat_MELSPECT')(y)                      \n",
        "                               \n",
        "# Apply 2 LSTM layer and one FC\n",
        "y = LSTM(256, return_sequences=False, dropout=0.2, name='LSTM_1')(y)\n",
        "y = Dense(eng_y_train.shape[1], activation='softmax', name='FC')(y)\n",
        "\n",
        "# Build final model\n",
        "model = Model(inputs=input_y, outputs=y)\n",
        "\n",
        "# Plot model graph\n",
        "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "Image(retina=True, filename='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmmUIBQSPLl2"
      },
      "source": [
        "# Compile model\n",
        "model.compile(optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.8), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Save best model\n",
        "best_model_save = ModelCheckpoint('/content/drive/MyDrive/Model/Nhận dạng/Model.h5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, verbose=1, mode='max')\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(eng_X_train,eng_y_train, batch_size=64, epochs=200, validation_data=(vie_X_test, vie_y_test), callbacks=[early_stopping, best_model_save])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrQe44fdO-lZ"
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ap3e1wPtPTi"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LLyIwGMtOTq"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhT1vgukaRf-"
      },
      "source": [
        "#Combine Eng + Vie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkX3itkIaUaN"
      },
      "source": [
        "from numpy import load\n",
        "\n",
        "eng_X_train = load('eng-vie_X_train.npy')\n",
        "vie_X_test = load('eng-vie_X_test.npy',)\n",
        "eng_y_train = load('eng_vie_y_train.npy',)\n",
        "vie_y_test = load('eng_vie_y_test.npy',)\n",
        "\n",
        "combined_X = np.concatenate((eng_X_train,vie_X_test))\n",
        "combined_y = np.concatenate((eng_y_train,vie_y_test))\n",
        "X_train,X_test,y_train,y_test = train_test_split(combined_X,combined_y,test_size=0.2,random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-xQ_CH3bzS8"
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "# Define two sets of inputs: MFCC and FBANK\n",
        "input_y = Input(shape=eng_X_train.shape[1:], name='Input_MELSPECT')\n",
        "\n",
        "## First LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_1_MELSPECT')(input_y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_1_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'), name='MaxPool_1_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_1_MELSPECT')(y)     \n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_2_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_2_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_2_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_2_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_3_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_3_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_3_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_3_MELSPECT')(y)\n",
        "\n",
        "## Second LFLB (local feature learning block)\n",
        "y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_4_MELSPECT')(y)\n",
        "y = TimeDistributed(BatchNormalization(), name='BatchNorm_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Activation('elu'), name='Activ_4_MELSPECT')(y)\n",
        "y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_4_MELSPECT')(y)\n",
        "y = TimeDistributed(Dropout(0.2), name='Drop_4_MELSPECT')(y)  \n",
        "\n",
        "## Flat\n",
        "y = TimeDistributed(Flatten(), name='Flat_MELSPECT')(y)                      \n",
        "                               \n",
        "# Apply 2 LSTM layer and one FC\n",
        "y = LSTM(256, return_sequences=False, dropout=0.2, name='LSTM_1')(y)\n",
        "y = Dense(eng_y_train.shape[1], activation='softmax', name='FC')(y)\n",
        "\n",
        "# Build final model\n",
        "model = Model(inputs=input_y, outputs=y)\n",
        "\n",
        "# Plot model graph\n",
        "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "Image(retina=True, filename='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t18DOHp8oL5B"
      },
      "source": [
        "# Compile model\n",
        "model.compile(optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.8), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Save best model\n",
        "best_model_save = ModelCheckpoint('/content/drive/MyDrive/Model/Nhận dạng/Model.h5', save_best_only=True, monitor='val_acc', mode='max')\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, verbose=1, mode='max')\n",
        "\n",
        "# Fit model\n",
        "history = model.fit(X_train,y_train, batch_size=64, epochs=150, validation_data=(X_test, y_test), callbacks=[early_stopping, best_model_save])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAAJDym_nodT"
      },
      "source": [
        "model.save('combined_my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GDQ-9oGtKT4"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7TPXrsttLUS"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZUJJ08ocZyO"
      },
      "source": [
        "Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-A1kLD8tMyz"
      },
      "source": [
        "combined_model = tf.keras.models.load_model('combined_my_model.h5')\n",
        "combined_model.evaluate(X_test,y_test,batch_size=32)\n",
        "\n",
        "y_pred = combined_model.predict(X_test,batch_size=32)\n",
        "true_labels = np.argwhere(y_test == 1)[:,1]\n",
        "pre_labels  = np.argwhere(y_pred==np.amax(y_pred,1, keepdims=True))[:,1]\n",
        "\n",
        "from mlxtend.evaluate import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "y_target =    [1, 1, 1, 0, 0, 2, 0, 3]\n",
        "y_predicted = [1, 0, 1, 0, 0, 2, 1, 3]\n",
        "\n",
        "cm = confusion_matrix(y_target=true_labels, \n",
        "                      y_predicted=pre_labels, \n",
        "                      binary=False)\n",
        "\n",
        "fig, ax = plot_confusion_matrix(cm)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSfScEYxdIuM"
      },
      "source": [
        "#Predict function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Y6L-G-dJ5t"
      },
      "source": [
        "def predict_emotion_from_file(model, filename, chunk_step=16000, chunk_size=49100, predict_proba=False, sample_rate=16000):\n",
        "        # Read audio file\n",
        "        emotion1={0:'Angry',1:'Happy',2:'Sad',3:'Neutral'}\n",
        "        y, sr = librosa.core.load(filename, sr=sample_rate, offset=0.5)\n",
        "        win_ts = 128\n",
        "        hop_ts = 64\n",
        "        if len(y) < max_pad_len:    \n",
        "          y_padded = np.zeros(max_pad_len)\n",
        "          y_padded[:len(y)] = y\n",
        "          y = y_padded\n",
        "        elif len(y) > max_pad_len:\n",
        "          y = np.asarray(y[:max_pad_len])\n",
        "        # Split audio signals into chunks\n",
        "        chunks = frame(y.reshape(1, 1, -1), chunk_step, chunk_size)\n",
        "        # Reshape chunks\n",
        "        chunks = chunks.reshape(chunks.shape[1],chunks.shape[-1])\n",
        "\n",
        "        # Z-normalization\n",
        "        y = np.asarray(list(map(zscore, chunks)))\n",
        "\n",
        "        # Compute mel spectrogram\n",
        "        mel_spect = np.asarray(list(map(mel_spectrogram, y)))\n",
        "\n",
        "        # Time distributed Framing\n",
        "        mel_spect_ts = frame(mel_spect,hop_ts,win_ts)\n",
        "        print(mel_spect_ts.shape)\n",
        "        # Build X for time distributed CNN\n",
        "        X = mel_spect_ts.reshape(mel_spect_ts.shape[0],\n",
        "                                    mel_spect_ts.shape[1],\n",
        "                                    mel_spect_ts.shape[2],\n",
        "                                    mel_spect_ts.shape[3],\n",
        "                                    1)\n",
        "        # Predict emotion\n",
        "        if predict_proba is True:\n",
        "            predict = model.predict(X)\n",
        "        else:\n",
        "            predict = np.argmax(model.predict(X), axis=1)\n",
        "            predict = [emotion1.get(emotion) for emotion in predict]\n",
        "\n",
        "        return predict"
      ],
      "execution_count": 64,
      "outputs": []
    }
  ]
}