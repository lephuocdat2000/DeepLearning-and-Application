{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled165.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOKm2JDwHf03QbpzbP5Cl3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lephuocdat2000/DeepLearning-and-Application/blob/main/SER/prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3D9zJU7DrI_",
        "outputId": "268223ca-f6c6-4ea5-b875-45b9bd3ba415"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15J4lzjzD5o8"
      },
      "source": [
        "import scipy.io.wavfile\n",
        "import numpy as np\n",
        "import sys\n",
        "import glob \n",
        "import librosa\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "from IPython.display import Audio\n",
        "### Time Distributed ConvNet imports ###\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed, concatenate\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, LeakyReLU, Flatten\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import Image\n",
        "from glob import glob\n",
        "import pickle\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from numpy import load\n",
        "### Audioimport ###\n",
        "import IPython\n",
        "\n",
        "### Warning ###\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QHCgh31uSzt",
        "outputId": "3210325a-d93c-492a-e827-81663a3f4941"
      },
      "source": [
        "cd /content/drive/MyDrive/Nhận dạng/combined_model/test "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Nhận dạng/combined_model/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV1y-bpyEAzK"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/Nhận dạng/combined_model/test/weights.136-1.27.h5')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QZZNUWAERJ1"
      },
      "source": [
        "win_ts = 128\n",
        "hop_ts = 64\n",
        "\n",
        "# Split spectrogram into frames\n",
        "def frame(x, win_step=128, win_size=64):\n",
        "    nb_frames = 1 + int((x.shape[2] - win_size) / win_step)\n",
        "    frames = np.zeros((x.shape[0], nb_frames, x.shape[1], win_size)).astype(np.float32)\n",
        "    for t in range(nb_frames):\n",
        "        frames[:,t,:,:] = np.copy(x[:,:,(t * win_step):(t * win_step + win_size)]).astype(np.float32)\n",
        "    return frames\n",
        "\n",
        "def mel_spectrogram(y, sr=16000, n_fft=512, win_length=256, hop_length=128, window='hamming', n_mels=128, fmax=4000):\n",
        "    \n",
        "    # Compute spectogram\n",
        "    mel_spect = np.abs(librosa.stft(y, n_fft=n_fft, window=window, win_length=win_length, hop_length=hop_length)) ** 2\n",
        "    # Compute mel spectrogram\n",
        "    mel_spect = librosa.feature.melspectrogram(S=mel_spect, sr=sr, n_mels=n_mels, fmax=fmax)\n",
        "    # Compute log-mel spectrogram\n",
        "    mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
        "    return mel_spect\n",
        "    \n",
        "def predict_emotion_from_file(model, filename, chunk_step=16000, chunk_size=49100, predict_proba=False, sample_rate=16000):\n",
        "        # Read audio file\n",
        "        emotion1={0:'Angry',1:'Happy',2:'Sad',3:'Neutral'}\n",
        "        y, sr = librosa.core.load(filename, sr=sample_rate, offset=0.5)\n",
        "   \n",
        "        win_ts = 128\n",
        "        hop_ts = 64\n",
        "        if len(y) < max_pad_len:    \n",
        "          y_padded = np.zeros(max_pad_len)\n",
        "          y_padded[:len(y)] = y\n",
        "          y = y_padded\n",
        "        elif len(y) > max_pad_len:\n",
        "          y = np.asarray(y[:max_pad_len])\n",
        "        # Split audio signals into chunks\n",
        "        chunks = frame(y.reshape(1, 1, -1), chunk_step, chunk_size)\n",
        "        # Reshape chunks\n",
        "        chunks = chunks.reshape(chunks.shape[1],chunks.shape[-1])\n",
        "        # Z-normalization\n",
        "        y = np.asarray(list(map(zscore, chunks)))\n",
        "\n",
        "        # Compute mel spectrogram\n",
        "        mel_spect = np.asarray(list(map(mel_spectrogram, y)))\n",
        "\n",
        "        # Time distributed Framing\n",
        "        mel_spect_ts = frame(mel_spect,hop_ts,win_ts)\n",
        "        # Build X for time distributed CNN\n",
        "        X = mel_spect_ts.reshape(mel_spect_ts.shape[0],\n",
        "                                    mel_spect_ts.shape[1],\n",
        "                                    mel_spect_ts.shape[2],\n",
        "                                    mel_spect_ts.shape[3],\n",
        "                                    1)\n",
        "        # Predict emotion\n",
        "        if predict_proba is True:\n",
        "            predict = model.predict(X)\n",
        "        else:\n",
        "            predict = np.argmax(model.predict(X), axis=1)\n",
        "            predict = [emotion1.get(emotion) for emotion in predict]\n",
        "        return predict"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf96_6IrFHSx",
        "outputId": "311e0a8b-b1af-4910-a0bd-42c95d551727"
      },
      "source": [
        "emotion1={0:'Angry',1:'Happy',2:'Sad',3:'Neutral'}\n",
        "file_emo='/content/0_2.wav'\n",
        "predict=predict_emotion_from_file(model,file_emo)\n",
        "print(predict)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Angry']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}